{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DX1-8jP2kRi5"
   },
   "source": [
    "# Interactive Machine Learning - Exercise 04\n",
    "\n",
    "\n",
    "## 0. Import the libraries\n",
    "As always we are providing a list useful packages in the import section below.\n",
    "Keep in mind that you can import additional libraries at any time and that you do not need to use all the imports if you know another solution for a given task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 529,
     "status": "ok",
     "timestamp": 1607265379601,
     "user": {
      "displayName": "Paul Mospan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gje-6RRBkrERIx7x0uSooTOdBI1tD7jeOCcJiH8=s64",
      "userId": "13717733502475344631"
     },
     "user_tz": -60
    },
    "id": "5f_cJexFogKu",
    "outputId": "75a3106d-0561-4403-a0ce-04ac73e55c35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 593,
     "status": "ok",
     "timestamp": 1607265449826,
     "user": {
      "displayName": "Paul Mospan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gje-6RRBkrERIx7x0uSooTOdBI1tD7jeOCcJiH8=s64",
      "userId": "13717733502475344631"
     },
     "user_tz": -60
    },
    "id": "4ioc0lX2kRi5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import random\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, clear_output\n",
    "from ipywidgets import interact_manual, GridspecLayout\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, MaxPooling2D\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from shutil import copyfile\n",
    "from lime import lime_image\n",
    "from skimage.segmentation import mark_boundaries\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gr0d5g3ekRi5",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1.Evaluation\n",
    "In this exercise you are supposed to write a method that evaluate one of your previously trained classifiers and\n",
    "allows you to gain initial insights into the inner workings of your model.\n",
    "You can choose freely whether you would like to use a model from exercise 02 or 03 or train a new model for all pokemon by yourself.\n",
    "After loading your model and the respective weights, create a prediction for each image in the validation-set of the respective dataset your model has been trained on.\n",
    "Afterwards, generate an output for each image containing the following information:\n",
    "\n",
    "* Image id\n",
    "* Image filename\n",
    "* Ground truth label\n",
    "* Prediction\n",
    "* Prediction probabilities sorted in ascending order with class names\n",
    "\n",
    "The output could have following form:\n",
    "\n",
    "* 1) b1.jpg Truth: 0 | Prediction 0 - [Bulbasaur:0.93, Vaporon: 0.04, Squirtle: 0.03, Pikachu: 0.00, Jolteon: 0.00, Evee: 0.00, Flareon: 0.00, Charmander: 0.00]\n",
    "* 2) ...\n",
    "* 3) ...\n",
    "\n",
    "Finally, examine all wrongly classified images and compare them visually to images of the predicted class.\n",
    "What do you notice? Are there any visual similarities that might lead your model to make the wrong prediction?\n",
    "\n",
    "NOTE: If you trained your model well, you might end up with 100% recognition rate on the validation set.\n",
    "In this case, for the sake of the exercise, follow this protocol:\n",
    "\n",
    "1) Accept gratulations for your superb model\n",
    "2) Choose an earlier checkpoint from this training\n",
    "3) Repeat till your model does not achieve 100% prediction accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dwehmqXpsykS"
   },
   "source": [
    "### 1. Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M0dek5rExg_0"
   },
   "source": [
    "#### X-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 104798,
     "status": "ok",
     "timestamp": 1607265557759,
     "user": {
      "displayName": "Paul Mospan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gje-6RRBkrERIx7x0uSooTOdBI1tD7jeOCcJiH8=s64",
      "userId": "13717733502475344631"
     },
     "user_tz": -60
    },
    "id": "8rnepVagsyLb",
    "outputId": "cd74e9c0-0070-4e21-e016-2b1782764a36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of proprocessed images: 347.The shape of one of the new preprocessed pictures in X_preprocessed: (224, 224, 3) \n"
     ]
    }
   ],
   "source": [
    "#PATH = '/content/gdrive/MyDrive/ColabData/pokemons/imgs/*'\n",
    "PATH = 'imgs/*'\n",
    "IMAGE_SIZE = (224, 224)\n",
    "\n",
    "X = [image.load_img(file, color_mode='rgb', target_size=IMAGE_SIZE, interpolation='nearest') for file in glob.glob(PATH)]\n",
    "X_array = [image.img_to_array(x_, data_format=None, dtype=None) for x_ in X]\n",
    "X_prep =  [preprocess_input(x_) for x_ in X_array]\n",
    "\n",
    "print(\"Number of proprocessed images: {}.The shape of one of the new preprocessed pictures in X_preprocessed: {} \".format(len(X_prep), X_prep[0].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y8SG-8N9wX9E"
   },
   "source": [
    "#### Y-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 662,
     "status": "ok",
     "timestamp": 1607265597795,
     "user": {
      "displayName": "Paul Mospan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gje-6RRBkrERIx7x0uSooTOdBI1tD7jeOCcJiH8=s64",
      "userId": "13717733502475344631"
     },
     "user_tz": -60
    },
    "id": "C4ObTGXis777",
    "outputId": "86a60881-95ac-4e6b-b939-9d4c4cf13ffb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of encoded labels: (347, 8), first three of them: \n",
      "[[0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "pokemons = ['bulbasaur', 'charmander', 'eevee', 'flareon', 'jolteon', 'pikachu', 'squirtle', 'vaporeon']\n",
    "\n",
    "# COLAB : path is equal to /content/gdrive/MyDrive/ColabData/pokemons/imgs/*\n",
    "# LOCAL: path is equal to imgs/*\n",
    "y = [pokemons.index(x.split('/')[1].split('_')[0].lower()) for x in glob.glob(PATH)]\n",
    "y_encoded = to_categorical(y, 8)\n",
    "print(\"The shape of encoded labels: {}, first three of them: \\n{}\".format(y_encoded.shape, y_encoded[:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wy3KInCojSPt"
   },
   "source": [
    "#### Test/val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 780,
     "status": "ok",
     "timestamp": 1607265599933,
     "user": {
      "displayName": "Paul Mospan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gje-6RRBkrERIx7x0uSooTOdBI1tD7jeOCcJiH8=s64",
      "userId": "13717733502475344631"
     },
     "user_tz": -60
    },
    "id": "VRrYIoaBs7_B",
    "outputId": "537390d4-d094-461d-fc7d-84ae6b34ea53"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((312, 224, 224, 3), (312, 8))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_prep_ndarray = np.array(X_prep, dtype=np.float32)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_prep_ndarray, y_encoded, train_size=0.9, random_state=42)\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "76J6w8nJxr74"
   },
   "source": [
    "#### Defining the network and loading weights of the model from previous exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9520,
     "status": "ok",
     "timestamp": 1607265610792,
     "user": {
      "displayName": "Paul Mospan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gje-6RRBkrERIx7x0uSooTOdBI1tD7jeOCcJiH8=s64",
      "userId": "13717733502475344631"
     },
     "user_tz": -60
    },
    "id": "ybNhVS4fs8CT",
    "outputId": "66477595-0513-4644-d2e3-6b2173592849"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> base_vgg summary: \n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 4,719,616\n",
      "Non-trainable params: 9,995,072\n",
      "_________________________________________________________________\n",
      ">>> model_vgg summary : \n",
      "Model: \"Model-XAI\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Functional)           (None, 7, 7, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              4719616   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 8200      \n",
      "=================================================================\n",
      "Total params: 20,492,104\n",
      "Trainable params: 10,497,032\n",
      "Non-trainable params: 9,995,072\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "base_vgg = VGG16(weights=\"imagenet\", include_top = False, input_shape=(224, 224, 3))\n",
    "base_vgg.trainable = True\n",
    "for layer in base_vgg.layers[0:16]:\n",
    "    layer.trainable =  False\n",
    "\n",
    "print('>>> base_vgg summary: ')\n",
    "base_vgg.summary()\n",
    "\n",
    "input_ = Input(shape=(224, 224, 3))\n",
    "concat_ = base_vgg(input_, training=False)\n",
    "maxpool_ = MaxPooling2D()(concat_)\n",
    "flatten_ = Flatten()(maxpool_)\n",
    "dense_1 = Dense(1024, activation='relu')(flatten_)\n",
    "dense_2 = Dense(1024, activation='relu')(dense_1)\n",
    "output_ = Dense(8, activation='softmax')(dense_2)\n",
    "model_vgg = Model(input_, output_)\n",
    "\n",
    "model_vgg._name = 'Model-XAI'\n",
    "#model_vgg.load_weights('/content/gdrive/MyDrive/ColabData/model_vgg-pokemons_on_imgs_weights.hdf5')\n",
    "model_vgg.load_weights('model_vgg-pokemons_on_imgs_weights.hdf5')\n",
    "\n",
    "print('>>> model_vgg summary : ')\n",
    "model_vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18215,
     "status": "ok",
     "timestamp": 1607265631063,
     "user": {
      "displayName": "Paul Mospan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gje-6RRBkrERIx7x0uSooTOdBI1tD7jeOCcJiH8=s64",
      "userId": "13717733502475344631"
     },
     "user_tz": -60
    },
    "id": "OYwFZx4Us8Ff",
    "outputId": "ea2d34ce-dc3a-4d6c-c279-34e10e785f7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1251 - acc: 0.9872\n",
      "Epoch 00001: val_acc improved from -inf to 1.00000, saving model to best_weights-XAI.hdf5\n",
      "10/10 [==============================] - 26s 3s/step - loss: 0.1251 - acc: 0.9872 - val_loss: 1.0218e-08 - val_acc: 1.0000\n",
      "Epoch 2/5\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0601 - acc: 0.9968 \n",
      "Epoch 00002: val_acc did not improve from 1.00000\n",
      "10/10 [==============================] - 118s 12s/step - loss: 0.0601 - acc: 0.9968 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0874 - acc: 0.9936\n",
      "Epoch 00003: val_acc did not improve from 1.00000\n",
      "10/10 [==============================] - 26s 3s/step - loss: 0.0874 - acc: 0.9936 - val_loss: 0.0333 - val_acc: 0.9714\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0150 - acc: 0.9936\n",
      "Epoch 00004: val_acc did not improve from 1.00000\n",
      "10/10 [==============================] - 27s 3s/step - loss: 0.0150 - acc: 0.9936 - val_loss: 1.3624e-07 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0176 - acc: 0.9936  \n",
      "Epoch 00005: val_acc did not improve from 1.00000\n",
      "10/10 [==============================] - 27s 3s/step - loss: 0.0176 - acc: 0.9936 - val_loss: 2.0605e-06 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Checkpoint to save the best model\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(filepath=\"best_weights-XAI.hdf5\", monitor = 'val_acc', verbose=1, save_best_only=True)\n",
    "\n",
    "model_vgg.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics='acc')\n",
    "\n",
    "history = model_vgg.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5, batch_size=32, callbacks = [checkpoint_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eMCbm_AXinUa"
   },
   "source": [
    "Creating a prediction and generating an output for each image containing the following information:\n",
    "*   Image id\n",
    "*   Image filename\n",
    "*   Ground truth label\n",
    "*   Prediction\n",
    "*   Prediction probabilities sorted in ascending order with class names \n",
    "\n",
    "The output could have following form:\n",
    "\n",
    "1) b1.jpg Truth: 0 | Prediction 0 - [Bulbasaur:0.93, Vaporon: 0.04, Squirtle: 0.03, Pikachu: 0.00, Jolteon: 0.00, Evee: 0.00, Flareon: 0.00, Charmander: 0.00]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i94etTD7xTsG"
   },
   "source": [
    "##### Building a list of path **A** to the images I trained my model on and then extracting names of these images **A_names**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 653,
     "status": "ok",
     "timestamp": 1607265974300,
     "user": {
      "displayName": "Paul Mospan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gje-6RRBkrERIx7x0uSooTOdBI1tD7jeOCcJiH8=s64",
      "userId": "13717733502475344631"
     },
     "user_tz": -60
    },
    "id": "4MAvlb2vrZFs",
    "outputId": "d233b623-9b79-48ad-926d-13c97cd7ee6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of paths to images : 347. Example of the path : <_io.BufferedReader name='imgs/PIKACHU_11.jpeg'>\n",
      "Number of names of images : 347. Example of the image name : PIKACHU_11.jpeg\n"
     ]
    }
   ],
   "source": [
    "A = [open(a_, 'rb') for a_ in glob.glob(PATH)]\n",
    "print('Number of paths to images : {}. Example of the path : {}'.format(len(A), A[0]))\n",
    "\n",
    "A_names = [a_.name.split('/')[1] for a_ in A]\n",
    "print('Number of names of images : {}. Example of the image name : {}'.format(len(A_names), A_names[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lOvLmpv70QUS"
   },
   "source": [
    "##### Splitting the list of images names exactly as train/val variables for comparison later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 801,
     "status": "ok",
     "timestamp": 1607265975939,
     "user": {
      "displayName": "Paul Mospan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gje-6RRBkrERIx7x0uSooTOdBI1tD7jeOCcJiH8=s64",
      "userId": "13717733502475344631"
     },
     "user_tz": -60
    },
    "id": "ZrZnz-smzpiE",
    "outputId": "26b908b2-9333-44aa-e3e7-63d0f3af86a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of validation images passed to model:  35\n",
      "Number of validation names must be equal to X_test:  35\n"
     ]
    }
   ],
   "source": [
    "A_train, A_test = train_test_split(A_names, train_size=0.9, random_state=42)\n",
    "\n",
    "print('Number of validation images passed to model: ', len(X_test))\n",
    "print('Number of validation names must be equal to X_test: ', len(A_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KezSWTW04V4O"
   },
   "source": [
    "#### Predicting on validation set, rounding up predictions and converting numpray ndarray to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 820,
     "status": "ok",
     "timestamp": 1607265977724,
     "user": {
      "displayName": "Paul Mospan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gje-6RRBkrERIx7x0uSooTOdBI1tD7jeOCcJiH8=s64",
      "userId": "13717733502475344631"
     },
     "user_tz": -60
    },
    "id": "ShFhsaNDZBQg"
   },
   "outputs": [],
   "source": [
    "y_proba = model_vgg.predict(X_test)\n",
    "y_proba_round = y_proba.round().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sDS-uZPIruhB"
   },
   "source": [
    "##### Functions needed for output of part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 1194,
     "status": "ok",
     "timestamp": 1607268628111,
     "user": {
      "displayName": "Paul Mospan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gje-6RRBkrERIx7x0uSooTOdBI1tD7jeOCcJiH8=s64",
      "userId": "13717733502475344631"
     },
     "user_tz": -60
    },
    "id": "osdcCZzT5F-B"
   },
   "outputs": [],
   "source": [
    "class_names = [\"BULBASAUR\", \"CHARMANDER\", \"EEVEE\", \"FLAREON\", \"JOLTEON\", \"PIKACHU\", \"SQUIRTLE\", \"VAPOREON\"]\n",
    "\n",
    "def find_truth(image):\n",
    "    \"\"\"\n",
    "    Function that finds groundtruth image label\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    image:   Receives images name along with it's number and extention.\n",
    "             Example: JOLTEON_19.jpg\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    groundtruth:  True label of the image.\n",
    "                  Example: JOLTEON\n",
    "    \"\"\"\n",
    "    image = image.split('_')[0]\n",
    "    groundtruth = class_names.index(image)\n",
    "    return groundtruth\n",
    "\n",
    "\n",
    "def make_dictionary(predictions):\n",
    "    \"\"\" \n",
    "    Function that takes predictions and binds them with respective label from class_name list\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    dict_sorted:  Sorted in descending order by value dictionary of label: prediction values\n",
    "    \"\"\"\n",
    "    dict_ = {}\n",
    "    for i in range(len(predictions)):\n",
    "        dict_[class_names[i]] = predictions[i]\n",
    "\n",
    "    dict_sorted = dict(\n",
    "        sorted(dict_.items(), key=operator.itemgetter(1), reverse=True))\n",
    "    return dict_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 559,
     "status": "ok",
     "timestamp": 1607265982276,
     "user": {
      "displayName": "Paul Mospan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gje-6RRBkrERIx7x0uSooTOdBI1tD7jeOCcJiH8=s64",
      "userId": "13717733502475344631"
     },
     "user_tz": -60
    },
    "id": "Yib5p2U45F5E",
    "outputId": "2ab1c18f-668a-48fd-cfb2-8c4e0f1ef8cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0) BULBASAUR_54.jpeg Truth: 0 | Prediction : 0 - {'BULBASAUR': 1.0, 'CHARMANDER': 0.0, 'EEVEE': 0.0, 'FLAREON': 0.0, 'JOLTEON': 0.0, 'PIKACHU': 0.0, 'SQUIRTLE': 0.0, 'VAPOREON': 0.0}\n",
      "1) SQUIRTLE_4.jpeg Truth: 6 | Prediction : 6 - {'SQUIRTLE': 1.0, 'BULBASAUR': 0.0, 'CHARMANDER': 0.0, 'EEVEE': 0.0, 'FLAREON': 0.0, 'JOLTEON': 0.0, 'PIKACHU': 0.0, 'VAPOREON': 0.0}\n",
      "2) CHARMANDER_40.jpeg Truth: 1 | Prediction : 1 - {'CHARMANDER': 1.0, 'BULBASAUR': 0.0, 'EEVEE': 0.0, 'FLAREON': 0.0, 'JOLTEON': 0.0, 'PIKACHU': 0.0, 'SQUIRTLE': 0.0, 'VAPOREON': 0.0}\n",
      "3) FLAREON_24.jpg Truth: 3 | Prediction : 3 - {'FLAREON': 1.0, 'BULBASAUR': 0.0, 'CHARMANDER': 0.0, 'EEVEE': 0.0, 'JOLTEON': 0.0, 'PIKACHU': 0.0, 'SQUIRTLE': 0.0, 'VAPOREON': 0.0}\n",
      "4) BULBASAUR_25.jpg Truth: 0 | Prediction : 0 - {'BULBASAUR': 1.0, 'CHARMANDER': 0.0, 'EEVEE': 0.0, 'FLAREON': 0.0, 'JOLTEON': 0.0, 'PIKACHU': 0.0, 'SQUIRTLE': 0.0, 'VAPOREON': 0.0}\n",
      "5) EEVEE_22.png Truth: 2 | Prediction : 2 - {'EEVEE': 1.0, 'BULBASAUR': 0.0, 'CHARMANDER': 0.0, 'FLAREON': 0.0, 'JOLTEON': 0.0, 'PIKACHU': 0.0, 'SQUIRTLE': 0.0, 'VAPOREON': 0.0}\n",
      "6) VAPOREON_4.jpg Truth: 7 | Prediction : 7 - {'VAPOREON': 1.0, 'BULBASAUR': 0.0, 'CHARMANDER': 0.0, 'EEVEE': 0.0, 'FLAREON': 0.0, 'JOLTEON': 0.0, 'PIKACHU': 0.0, 'SQUIRTLE': 0.0}\n",
      "7) EEVEE_13.png Truth: 2 | Prediction : 2 - {'EEVEE': 1.0, 'BULBASAUR': 0.0, 'CHARMANDER': 0.0, 'FLAREON': 0.0, 'JOLTEON': 0.0, 'PIKACHU': 0.0, 'SQUIRTLE': 0.0, 'VAPOREON': 0.0}\n",
      "8) PIKACHU_18.jpeg Truth: 5 | Prediction : 5 - {'PIKACHU': 1.0, 'BULBASAUR': 0.0, 'CHARMANDER': 0.0, 'EEVEE': 0.0, 'FLAREON': 0.0, 'JOLTEON': 0.0, 'SQUIRTLE': 0.0, 'VAPOREON': 0.0}\n",
      "9) BULBASAUR_46.jpeg Truth: 0 | Prediction : 0 - {'BULBASAUR': 1.0, 'CHARMANDER': 0.0, 'EEVEE': 0.0, 'FLAREON': 0.0, 'JOLTEON': 0.0, 'PIKACHU': 0.0, 'SQUIRTLE': 0.0, 'VAPOREON': 0.0}\n",
      "10) JOLTEON_16.jpg Truth: 4 | Prediction : 4 - {'JOLTEON': 1.0, 'BULBASAUR': 0.0, 'CHARMANDER': 0.0, 'EEVEE': 0.0, 'FLAREON': 0.0, 'PIKACHU': 0.0, 'SQUIRTLE': 0.0, 'VAPOREON': 0.0}\n",
      "11) BULBASAUR_53.jpeg Truth: 0 | Prediction : 0 - {'BULBASAUR': 1.0, 'CHARMANDER': 0.0, 'EEVEE': 0.0, 'FLAREON': 0.0, 'JOLTEON': 0.0, 'PIKACHU': 0.0, 'SQUIRTLE': 0.0, 'VAPOREON': 0.0}\n",
      "12) EEVEE_21.jpg Truth: 2 | Prediction : 2 - {'EEVEE': 1.0, 'BULBASAUR': 0.0, 'CHARMANDER': 0.0, 'FLAREON': 0.0, 'JOLTEON': 0.0, 'PIKACHU': 0.0, 'SQUIRTLE': 0.0, 'VAPOREON': 0.0}\n",
      "13) FLAREON_16.jpg Truth: 3 | Prediction : 3 - {'FLAREON': 1.0, 'BULBASAUR': 0.0, 'CHARMANDER': 0.0, 'EEVEE': 0.0, 'JOLTEON': 0.0, 'PIKACHU': 0.0, 'SQUIRTLE': 0.0, 'VAPOREON': 0.0}\n",
      "14) PIKACHU_14.jpeg Truth: 5 | Prediction : 5 - {'PIKACHU': 1.0, 'BULBASAUR': 0.0, 'CHARMANDER': 0.0, 'EEVEE': 0.0, 'FLAREON': 0.0, 'JOLTEON': 0.0, 'SQUIRTLE': 0.0, 'VAPOREON': 0.0}\n",
      "15) PIKACHU_32.jpg Truth: 5 | Prediction : 5 - {'PIKACHU': 1.0, 'BULBASAUR': 0.0, 'CHARMANDER': 0.0, 'EEVEE': 0.0, 'FLAREON': 0.0, 'JOLTEON': 0.0, 'SQUIRTLE': 0.0, 'VAPOREON': 0.0}\n",
      "16) BULBASAUR_34.jpeg Truth: 0 | Prediction : 0 - {'BULBASAUR': 1.0, 'CHARMANDER': 0.0, 'EEVEE': 0.0, 'FLAREON': 0.0, 'JOLTEON': 0.0, 'PIKACHU': 0.0, 'SQUIRTLE': 0.0, 'VAPOREON': 0.0}\n",
      "17) VAPOREON_12.jpg Truth: 7 | Prediction : 7 - {'VAPOREON': 1.0, 'BULBASAUR': 0.0, 'CHARMANDER': 0.0, 'EEVEE': 0.0, 'FLAREON': 0.0, 'JOLTEON': 0.0, 'PIKACHU': 0.0, 'SQUIRTLE': 0.0}\n",
      "18) PIKACHU_31.jpg Truth: 5 | Prediction : 5 - {'PIKACHU': 1.0, 'BULBASAUR': 0.0, 'CHARMANDER': 0.0, 'EEVEE': 0.0, 'FLAREON': 0.0, 'JOLTEON': 0.0, 'SQUIRTLE': 0.0, 'VAPOREON': 0.0}\n",
      "19) SQUIRTLE_30.jpg Truth: 6 | Prediction : 6 - {'SQUIRTLE': 1.0, 'BULBASAUR': 0.0, 'CHARMANDER': 0.0, 'EEVEE': 0.0, 'FLAREON': 0.0, 'JOLTEON': 0.0, 'PIKACHU': 0.0, 'VAPOREON': 0.0}\n",
      "20) VAPOREON_1.jpg Truth: 7 | Prediction : 7 - {'VAPOREON': 1.0, 'BULBASAUR': 0.0, 'CHARMANDER': 0.0, 'EEVEE': 0.0, 'FLAREON': 0.0, 'JOLTEON': 0.0, 'PIKACHU': 0.0, 'SQUIRTLE': 0.0}\n",
      "21) BULBASAUR_15.jpg Truth: 0 | Prediction : 0 - {'BULBASAUR': 1.0, 'CHARMANDER': 0.0, 'EEVEE': 0.0, 'FLAREON': 0.0, 'JOLTEON': 0.0, 'PIKACHU': 0.0, 'SQUIRTLE': 0.0, 'VAPOREON': 0.0}\n",
      "22) BULBASAUR_18.jpg Truth: 0 | Prediction : 0 - {'BULBASAUR': 1.0, 'CHARMANDER': 0.0, 'EEVEE': 0.0, 'FLAREON': 0.0, 'JOLTEON': 0.0, 'PIKACHU': 0.0, 'SQUIRTLE': 0.0, 'VAPOREON': 0.0}\n",
      "23) PIKACHU_0.png Truth: 5 | Prediction : 5 - {'PIKACHU': 1.0, 'BULBASAUR': 0.0, 'CHARMANDER': 0.0, 'EEVEE': 0.0, 'FLAREON': 0.0, 'JOLTEON': 0.0, 'SQUIRTLE': 0.0, 'VAPOREON': 0.0}\n",
      "24) FLAREON_15.jpg Truth: 3 | Prediction : 3 - {'FLAREON': 1.0, 'BULBASAUR': 0.0, 'CHARMANDER': 0.0, 'EEVEE': 0.0, 'JOLTEON': 0.0, 'PIKACHU': 0.0, 'SQUIRTLE': 0.0, 'VAPOREON': 0.0}\n",
      "25) EEVEE_6.jpg Truth: 2 | Prediction : 2 - {'EEVEE': 1.0, 'BULBASAUR': 0.0, 'CHARMANDER': 0.0, 'FLAREON': 0.0, 'JOLTEON': 0.0, 'PIKACHU': 0.0, 'SQUIRTLE': 0.0, 'VAPOREON': 0.0}\n",
      "26) VAPOREON_29.jpg Truth: 7 | Prediction : 7 - {'VAPOREON': 1.0, 'BULBASAUR': 0.0, 'CHARMANDER': 0.0, 'EEVEE': 0.0, 'FLAREON': 0.0, 'JOLTEON': 0.0, 'PIKACHU': 0.0, 'SQUIRTLE': 0.0}\n",
      "27) CHARMANDER_4.jpeg Truth: 1 | Prediction : 1 - {'CHARMANDER': 1.0, 'BULBASAUR': 0.0, 'EEVEE': 0.0, 'FLAREON': 0.0, 'JOLTEON': 0.0, 'PIKACHU': 0.0, 'SQUIRTLE': 0.0, 'VAPOREON': 0.0}\n",
      "28) CHARMANDER_3.jpeg Truth: 1 | Prediction : 1 - {'CHARMANDER': 1.0, 'BULBASAUR': 0.0, 'EEVEE': 0.0, 'FLAREON': 0.0, 'JOLTEON': 0.0, 'PIKACHU': 0.0, 'SQUIRTLE': 0.0, 'VAPOREON': 0.0}\n",
      "29) BULBASAUR_8.jpeg Truth: 0 | Prediction : 0 - {'BULBASAUR': 1.0, 'CHARMANDER': 0.0, 'EEVEE': 0.0, 'FLAREON': 0.0, 'JOLTEON': 0.0, 'PIKACHU': 0.0, 'SQUIRTLE': 0.0, 'VAPOREON': 0.0}\n",
      "30) PIKACHU_40.png Truth: 5 | Prediction : 5 - {'PIKACHU': 1.0, 'BULBASAUR': 0.0, 'CHARMANDER': 0.0, 'EEVEE': 0.0, 'FLAREON': 0.0, 'JOLTEON': 0.0, 'SQUIRTLE': 0.0, 'VAPOREON': 0.0}\n",
      "31) SQUIRTLE_36.jpg Truth: 6 | Prediction : 6 - {'SQUIRTLE': 1.0, 'BULBASAUR': 0.0, 'CHARMANDER': 0.0, 'EEVEE': 0.0, 'FLAREON': 0.0, 'JOLTEON': 0.0, 'PIKACHU': 0.0, 'VAPOREON': 0.0}\n",
      "32) EEVEE_7.jpg Truth: 2 | Prediction : 2 - {'EEVEE': 1.0, 'BULBASAUR': 0.0, 'CHARMANDER': 0.0, 'FLAREON': 0.0, 'JOLTEON': 0.0, 'PIKACHU': 0.0, 'SQUIRTLE': 0.0, 'VAPOREON': 0.0}\n",
      "33) JOLTEON_30.jpg Truth: 4 | Prediction : 4 - {'JOLTEON': 1.0, 'BULBASAUR': 0.0, 'CHARMANDER': 0.0, 'EEVEE': 0.0, 'FLAREON': 0.0, 'PIKACHU': 0.0, 'SQUIRTLE': 0.0, 'VAPOREON': 0.0}\n",
      "34) FLAREON_6.png Truth: 3 | Prediction : 3 - {'FLAREON': 1.0, 'BULBASAUR': 0.0, 'CHARMANDER': 0.0, 'EEVEE': 0.0, 'JOLTEON': 0.0, 'PIKACHU': 0.0, 'SQUIRTLE': 0.0, 'VAPOREON': 0.0}\n"
     ]
    }
   ],
   "source": [
    "for i in range(35):\n",
    "    groundtruth = find_truth(A_test[i])\n",
    "    # max value in predictions\n",
    "    max_pred = y_proba_round[i].index(max(y_proba_round[i]))\n",
    "    # dictionary of label : prediction vales\n",
    "    dict_ = make_dictionary(y_proba_round[i])\n",
    "    print('{}) {} Truth: {} | Prediction : {} - {}'.format(\n",
    "        i, A_test[i], groundtruth, max_pred, dict_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CO3CxyIFs6Rs"
   },
   "source": [
    "## QUESTION: Finally, examine all wrongly classified images and compare them visually to images of the predicted class. What do you notice? Are there any visual similarities that might lead your model to make the wrong prediction?\n",
    "\n",
    "## ANSWER: My model yields no indiferences and every image has 100% probability prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eE1sX38VkRi6"
   },
   "source": [
    "### 2. Filtering\n",
    "In this exercise you will build your own user interface to explore the outputs of specific layers of your network.\n",
    "The goal is to let a user interactively load an image and then visualize the output of a chosen convolutional layer from the trained networrk for this image.\n",
    "This UI could look like this, but  feel free to change elements as you like:\n",
    "\n",
    "* A textfield to specify the path of the input image\n",
    "* A button to confirm the image\n",
    "* A dropdown that lets the user choose the convolutional layer\n",
    "* A plot of the input image\n",
    "* A slider to choose which feature map (channel) from the output of the convolutional layer should be displayed\n",
    "* A plot of this feature map\n",
    "\n",
    "The final UI could look like this\n",
    "![](https://hcm-lab.de/cloud/index.php/s/aa74Cf5EF7rjxk9/preview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding convolutional layers and number of filters needed for this task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'block1_conv1': 64,\n",
       " 'block1_conv2': 64,\n",
       " 'block2_conv1': 128,\n",
       " 'block2_conv2': 128,\n",
       " 'block3_conv1': 256,\n",
       " 'block3_conv2': 256,\n",
       " 'block3_conv3': 256,\n",
       " 'block4_conv1': 512,\n",
       " 'block4_conv2': 512,\n",
       " 'block4_conv3': 512,\n",
       " 'block5_conv1': 512,\n",
       " 'block5_conv2': 512,\n",
       " 'block5_conv3': 512}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layers = []\n",
    "conv_layers_filters = {}\n",
    "\n",
    "for layer in base_vgg.layers:\n",
    "    # check for convolutional layer\n",
    "    if 'conv' not in layer.name:\n",
    "        continue\n",
    "    # get filter weights\n",
    "    filters, biases = layer.get_weights()\n",
    "    conv_layers.append(layer.name)\n",
    "    conv_layers_filters[layer.name] = filters.shape[3]\n",
    "\n",
    "conv_layers_filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Zg2AresLPB3"
   },
   "source": [
    "### Methods to create widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 629,
     "status": "ok",
     "timestamp": 1607267113028,
     "user": {
      "displayName": "Paul Mospan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gje-6RRBkrERIx7x0uSooTOdBI1tD7jeOCcJiH8=s64",
      "userId": "13717733502475344631"
     },
     "user_tz": -60
    },
    "id": "9_qa2ATQFCo9"
   },
   "outputs": [],
   "source": [
    "textfield = widgets.Text(value='PIKACHU_40.png', placeholder='Your image', description='Image path:')\n",
    "\n",
    "def create_textfield():\n",
    "    return textfield\n",
    "\n",
    "\n",
    "def create_interact_button():\n",
    "    button = widgets.Button(description='Run Interact', button_style='success')\n",
    "    button.on_click(on_interact)\n",
    "    return button\n",
    "\n",
    "\n",
    "def create_image_original(path_to_image=''):\n",
    "    if path_to_image == '':\n",
    "        return widgets.Textarea(value='You need to select an image first')\n",
    "    else:\n",
    "        file = open(path_to_image, \"rb\")\n",
    "        image = file.read()\n",
    "        return widgets.Image(value=image)\n",
    "\n",
    "\n",
    "dropdown = widgets.Dropdown(options=conv_layers, description='Conv Layer:',continuous_update=True)\n",
    "\n",
    "def create_conv_dropdown():\n",
    "    return dropdown\n",
    "\n",
    "\n",
    "filter_ = widgets.IntSlider(value = 10, min = 0, max = 64, step = 1,description = 'Output filter:',\n",
    "                           continuous_update = False, orientation = 'horizontal', readout = True, readout_format = 'd')\n",
    "\n",
    "def create_conv_button():\n",
    "    button = widgets.Button(description='Select Conv Layer', button_style='info')\n",
    "    button.on_click(on_conv_layer)\n",
    "    return button\n",
    "\n",
    "def create_filter(filter_number):\n",
    "    filter_.max = filter_number\n",
    "    return filter_\n",
    "\n",
    "def create_filter_button():\n",
    "    button = widgets.Button(description='Select Filter', button_style='warning')\n",
    "    button.on_click(on_filter)\n",
    "    return button"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This next cell performs image preprocessing, convolution layer matchins etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the outputs of the base_model where all convolutions are\n",
    "layer_outputs = [layer.output for layer in base_vgg.layers] \n",
    "\n",
    "# Creating a model that will return these outputs, given the model input\n",
    "activation_model = Model(inputs=base_vgg.input, outputs=layer_outputs) \n",
    "\n",
    "def image_preprocess(img_path):\n",
    "    \"\"\"\n",
    "    This function takes an image, preprocesses it for model and eturns a list of five Numpy arrays: one array per layer activation\n",
    "    \"\"\"\n",
    "    #IMAGE_SIZE is equal to (224,224)\n",
    "    img = image.load_img(img_path, target_size=IMAGE_SIZE)\n",
    "    img_tensor = image.img_to_array(img)\n",
    "\n",
    "    img_prep = preprocess_input(img_tensor) \n",
    "    img_array = np.array(img_prep, dtype=np.float32)\n",
    "    img_ready = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    activations = activation_model.predict(img_ready) \n",
    "    return(activations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AO3OAKIdLUzH"
   },
   "source": [
    "### Collable methods by widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 670,
     "status": "ok",
     "timestamp": 1607265994780,
     "user": {
      "displayName": "Paul Mospan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gje-6RRBkrERIx7x0uSooTOdBI1tD7jeOCcJiH8=s64",
      "userId": "13717733502475344631"
     },
     "user_tz": -60
    },
    "id": "8zljmkHDFCzy"
   },
   "outputs": [],
   "source": [
    "full_path = ''\n",
    "conv_block = ''\n",
    "filter_number = 0\n",
    "\n",
    "def on_interact(button):\n",
    "    \"\"\"\n",
    "    This function displays chosen by path image\n",
    "    \"\"\"\n",
    "    #PATH_TO_IMAGES = '/content/gdrive/MyDrive/ColabData/pokemons/imgs/'\n",
    "    PATH_TO_IMAGES = 'imgs/'\n",
    "    global full_path\n",
    "    full_path = PATH_TO_IMAGES + textfield.value\n",
    "    grid[2, 0] = create_image_original(full_path)\n",
    "\n",
    "def on_conv_layer(button):\n",
    "    \"\"\"\n",
    "    This function creates filter slider and sets max values for it\n",
    "    \"\"\"\n",
    "    global conv_block\n",
    "    conv_block = dropdown.value\n",
    "    grid[2, 1] = create_filter(conv_layers_filters.get(conv_block))\n",
    "    grid[3, 1] = create_filter_button()\n",
    "\n",
    "# A list of all layers in conv model\n",
    "conv_block_list = []\n",
    "for layer in base_vgg.layers:\n",
    "    conv_block_list.append(layer.name)\n",
    "\n",
    "def on_filter(button):\n",
    "    \"\"\"\n",
    "    This function yields final path to image, selected convolutional block and chosen filter\n",
    "    \"\"\"\n",
    "    global filter_number\n",
    "    filter_number = filter_.value\n",
    "    print('image: {}, conv_block: {}, filter: {}'.format(full_path, conv_block, filter_number))\n",
    "    \n",
    "    activation_layers = image_preprocess(full_path)\n",
    "    activation_layer = activation_layers[conv_block_list.index(conv_block)]\n",
    "    print('activation_layer shape: ', activation_layer.shape)\n",
    "    plt.matshow(activation_layer[0, :, :, filter_number-1], cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1LfHdeZ8LYs7"
   },
   "source": [
    "### Layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 817,
     "referenced_widgets": [
      "9eaae5aab7bc45f7b493af8129e406b5",
      "c8d80d9bf0354ff8ba81c7583c1f0195",
      "d4e5923a4fbb4a249fe4e992fda46860",
      "137164e5ddeb4286a36f7351b4b7789d",
      "95258d3ad37e4b25b90030b05ecaea2d",
      "731b42ce36f94188b978c8e1586975dd",
      "92a4ed17154d482a907d09c09df8b40b",
      "b9e0b6bb88b1489883af485018b2afa6",
      "7bec90bc1bbe4191adffb3c609a19ee9",
      "195c211ba82f427f8242c5a2f8f8d293",
      "4dc1188baae64b72bd73a5d91b7f175a",
      "f3f955ac8b194748bda5e2b640296fbf",
      "8c638a40f00f4a05aca68da623cda0fd",
      "46dc8b137e3b4e91a7034d4a8a9205a5",
      "d2bc3ee79d6a408e8f1dad5f2ba4e67d",
      "d68b969a206241a8aedb73cd09f673cb",
      "18acb773a2364af5b4195c3c9125a6dc",
      "ab185a05edf342e3a7fb83169402f2aa",
      "7f8c9134aa5f4cacb1bb45885cda19c6",
      "154d7dea4a874034a63983824c3cc66f"
     ]
    },
    "executionInfo": {
     "elapsed": 668,
     "status": "ok",
     "timestamp": 1607267116868,
     "user": {
      "displayName": "Paul Mospan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gje-6RRBkrERIx7x0uSooTOdBI1tD7jeOCcJiH8=s64",
      "userId": "13717733502475344631"
     },
     "user_tz": -60
    },
    "id": "4ipyr2wrFC5C",
    "outputId": "46442e7d-7302-4314-9f93-8469945a4fb2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aa5d38f03d34622b03a4f87a49e5285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GridspecLayout(children=(Text(value='PIKACHU_40.png', description='Image path:', layout=Layout(grid_area='widgâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image: imgs/PIKACHU_40.png, conv_block: block3_conv1, filter: 120\n",
      "activation_layer shape:  (1, 56, 56, 256)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid = GridspecLayout(4, 2, height='600px')\n",
    "\n",
    "# left part of the layout\n",
    "grid[0, 0] = create_textfield()\n",
    "grid[1, 0] = create_interact_button()\n",
    "grid[2, 0] = create_image_original()\n",
    "\n",
    "# right part of the layout\n",
    "grid[0, 1] = create_conv_dropdown()\n",
    "grid[1, 1] = create_conv_button()\n",
    "#grid[2, 1] = create_filter()\n",
    "#grid[3, 1] = create_filter_button()\n",
    "\n",
    "display(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PQAronppkRi6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 2. Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "myaAyC98kRi6",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3. Explanations\n",
    "In this exercise we will use the LIME framework to generate explanations for the preditions of our model.\n",
    "To this end you will extend your evaluation of exercise 1 by adding the LIME ImageExplainer.\n",
    "For assistance, you can check out the example Images with keras from the official github repo [here](https://github.com/marcotcr/lime).\n",
    "\n",
    "As presented in the slides ```num_samples``` and ```num_features``` are the most important parts you can tweak in the lime algorithm.\n",
    "Try to find a suitable tradeoff between the accuracy of the explanations and the overall runtime, for your specific model, by adjusting those parameters accordingly.\n",
    "Good values to start with are ```num_features```= 5, ```num_samples```= 800.\n",
    "Moreover, Lime provides the possibility to filter the superpixels regarding their contributions towards the explanation.\n",
    "The ```get_image_and_mask``` method has a ```min_weight``` argument which corresponds to the minimum weight of the superpixels\n",
    " to include in the explanation. This value can be useful to create meaningful explanations. You can start with setting\n",
    " ```min_weight``` to 0.1 and adjust accordingly.\n",
    "\n",
    "After generating explanations with LIME, repeat the analysis of the wrongly classified images similar to exercise 1.\n",
    "Have your initial assumptions been correct?\n",
    "Briefly write down your insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ui-NEHpskRi6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 3. Code here"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "xai_notebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "137164e5ddeb4286a36f7351b4b7789d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "success",
      "description": "Run Interact",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_f3f955ac8b194748bda5e2b640296fbf",
      "style": "IPY_MODEL_4dc1188baae64b72bd73a5d91b7f175a",
      "tooltip": ""
     }
    },
    "154d7dea4a874034a63983824c3cc66f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": "widget006",
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "18acb773a2364af5b4195c3c9125a6dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "SliderStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "SliderStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": "",
      "handle_color": null
     }
    },
    "195c211ba82f427f8242c5a2f8f8d293": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": "widget001",
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "46dc8b137e3b4e91a7034d4a8a9205a5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": "widget003",
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4dc1188baae64b72bd73a5d91b7f175a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "731b42ce36f94188b978c8e1586975dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DropdownModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DropdownModel",
      "_options_labels": [
       "1",
       "2",
       "3"
      ],
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "DropdownView",
      "description": "Number:",
      "description_tooltip": null,
      "disabled": false,
      "index": 1,
      "layout": "IPY_MODEL_d68b969a206241a8aedb73cd09f673cb",
      "style": "IPY_MODEL_d2bc3ee79d6a408e8f1dad5f2ba4e67d"
     }
    },
    "7bec90bc1bbe4191adffb3c609a19ee9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7f8c9134aa5f4cacb1bb45885cda19c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8c638a40f00f4a05aca68da623cda0fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "92a4ed17154d482a907d09c09df8b40b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntSliderModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntSliderModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "IntSliderView",
      "continuous_update": false,
      "description": "Output filter:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_ab185a05edf342e3a7fb83169402f2aa",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "readout": true,
      "readout_format": "d",
      "step": 5,
      "style": "IPY_MODEL_18acb773a2364af5b4195c3c9125a6dc",
      "value": 95
     }
    },
    "95258d3ad37e4b25b90030b05ecaea2d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "TextareaModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "TextareaModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "TextareaView",
      "continuous_update": true,
      "description": "",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_46dc8b137e3b4e91a7034d4a8a9205a5",
      "placeholder": "â€‹",
      "rows": null,
      "style": "IPY_MODEL_8c638a40f00f4a05aca68da623cda0fd",
      "value": "You need to select an image first"
     }
    },
    "9eaae5aab7bc45f7b493af8129e406b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "GridBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "GridBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "GridBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d4e5923a4fbb4a249fe4e992fda46860",
       "IPY_MODEL_137164e5ddeb4286a36f7351b4b7789d",
       "IPY_MODEL_95258d3ad37e4b25b90030b05ecaea2d",
       "IPY_MODEL_731b42ce36f94188b978c8e1586975dd",
       "IPY_MODEL_92a4ed17154d482a907d09c09df8b40b",
       "IPY_MODEL_b9e0b6bb88b1489883af485018b2afa6"
      ],
      "layout": "IPY_MODEL_c8d80d9bf0354ff8ba81c7583c1f0195"
     }
    },
    "ab185a05edf342e3a7fb83169402f2aa": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": "widget005",
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b9e0b6bb88b1489883af485018b2afa6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "TextareaModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "TextareaModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "TextareaView",
      "continuous_update": true,
      "description": "",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_154d7dea4a874034a63983824c3cc66f",
      "placeholder": "â€‹",
      "rows": null,
      "style": "IPY_MODEL_7f8c9134aa5f4cacb1bb45885cda19c6",
      "value": "You need to select an image and it's convolutional layer"
     }
    },
    "c8d80d9bf0354ff8ba81c7583c1f0195": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": "\"widget001 widget004\"\n\"widget002 widget005\"\n\"widget003 widget006\"",
      "grid_template_columns": "repeat(2, 1fr)",
      "grid_template_rows": "repeat(3, 1fr)",
      "height": "800px",
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d2bc3ee79d6a408e8f1dad5f2ba4e67d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d4e5923a4fbb4a249fe4e992fda46860": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "TextModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "TextModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "TextView",
      "continuous_update": true,
      "description": "Image path:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_195c211ba82f427f8242c5a2f8f8d293",
      "placeholder": "Your image",
      "style": "IPY_MODEL_7bec90bc1bbe4191adffb3c609a19ee9",
      "value": "EEVEE_15.png"
     }
    },
    "d68b969a206241a8aedb73cd09f673cb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": "widget004",
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f3f955ac8b194748bda5e2b640296fbf": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": "widget002",
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
