{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Machine Learning - Exercise 03\n",
    "\n",
    "In this exercise we will learn about cooperative machine learning.\n",
    "Our goal is it to build a very basic cooperative machine learning user interface and use it to extend our Pokedex model from the last exercise.\n",
    "\n",
    "The steps you are going to cover are as follows:\n",
    "* Pretrain our Pokedex model with the original data\n",
    "* Manually label a small bit of new data\n",
    "* Train our model on the new data\n",
    "* Use the model in a cooperative workflow to annotate the rest of the dataset\n",
    "\n",
    "Please read each exercise carefully before you start coding! You will find a number in the comments before each step of coding you will do. Please refer to these numbers if you have any questions.\n",
    "\n",
    "## 0. Import the libraries\n",
    "As always we are providing a list useful packages in the import section below.\n",
    "Keep in mind that you can import additional libraries at any time and that you do not need to use all the imports if you know another solution for a given task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import random\n",
    "from IPython.display import Image\n",
    "from ipywidgets import interact_manual\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pretrain the model\n",
    "In this part we are going to pretrain our model on the pokemon images you already know.\n",
    "To this end we will use the same VGG16 model as last week with the following training procedure:\n",
    "\n",
    "Preprocessing:\n",
    "* Imagesize (224,224)\n",
    "* Vgg16 standard preprocessing from the Keras framework\n",
    "\n",
    "Datasplit:\n",
    "* Use 90% of the data to train and 10% to valitdate your results\n",
    "\n",
    "Training 1:\n",
    "* Initialize the model with the imagenet weights\n",
    "* Freeze all convolution layers\n",
    "* Train the model using the following settings:\n",
    " * 5 Epochs\n",
    " * Adam Optimizer with default Parameters\n",
    " * categorical cross entropy loss\n",
    " * Batchsize 32\n",
    "\n",
    "Training 2:\n",
    "*  Unfreeze the last two convolutional Blocks\n",
    "*  Continue training with the following settings:\n",
    " * 10 Epochs\n",
    " * Adam Optimizer with a learning rate of 0.0001\n",
    " * Batchsize of 32\n",
    "\n",
    "A convolutional Block in the VGG16 architecture consists of 2 to 3 Conv Layers and on Pooling layer.\n",
    "You can access a models layer directly via `model.layers`.\n",
    "Read up on how to freeze layers [here](https://keras.io/guides/transfer_learning/), in case you did not use this technique in the last exercise.\n",
    "Your model should achieve a validation accuracy of close to 100% ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Load data for pretraining and apply preprocessing\n",
    "\n",
    "# 2. Split data into training and test partition\n",
    "\n",
    "# 3. Define network\n",
    "\n",
    "# 4. Freeze weights and perform training step 1\n",
    "\n",
    "# 5. Unfreeze weights and perform training step 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pretrain the model\n",
    "Now that we have our initial model we are going to extend it with some more pokemon.\n",
    "[Here](https://megastore.uni-augsburg.de/get/OxpI3M_JyU/) you will find roughly 6000 images of the following Pokemon:\n",
    "* Blastoise\n",
    "* Charizard\n",
    "* Charmeleon\n",
    "* Ivysaur\n",
    "* Venusaur\n",
    "* Wartortle\n",
    "\n",
    "Unfortunately images are not labeled yet. To speed things up a bit we are only going to label a small part of the data ourselves, and then build a model to help us doing the rest.\n",
    "(Actually this will probably not be faster, but more fun anyway :) ).\n",
    "In your project directory you will find a 'data_labled' folder, which we will use to store the labeled data.\n",
    "This time we will use the folder structure to create our labels and train / validation partitions.\n",
    "Inside the folder you will therefore find a 'train' and an 'val' folder, each of them containing subfolders for each class.\n",
    "\n",
    "In the following step you should at first manually pick at least 5 examples per class and copy them from the 'data' folder to the train partition of the 'data_labeled' folder.\n",
    "To then take full advantage of the current way the data is structured, we will use keras data generators in combination with the `flow_from_directory` to dynamically read the input data and feed it to our model.\n",
    "You can find an example of such data generators [here](https://keras.io/api/preprocessing/image/#flowfromdirectory-method).\n",
    "\n",
    "Specifically we are going to write a function `train_loop()` which creates two data generators (one for training and one for validation) and trains a model for the new Images on features extracted from our current Pokexedx model.\n",
    "To this end you can simply rebuild the structure of the original model, but replace the number of output classes.\n",
    "To load the weights you can then use the following code snippet:\n",
    "`model.layers[-1]._name = 'new_output'`</br>\n",
    "`model.load_weights(weight_path, by_name=True)`</br>\n",
    "\n",
    "Freeze all layers but the dense layers, we will only need those and want to speed up the training process a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 6. Copy at least 5 images per class from the data folder to the correct partition in the data_labeled folder\n",
    "\n",
    "# 7. Write a function train_loop()\n",
    "\n",
    "def train_loop():\n",
    "\n",
    "    # 8. Build model\n",
    "\n",
    "    # 9. Load weights\n",
    "\n",
    "    # 10. Build data generators\n",
    "\n",
    "    # 11. Fit the model to the data for a few epochs\n",
    "\n",
    "# 12. Call train loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Interactive UI\n",
    "\n",
    "In this part of the exercise we are going to put our pretrained model to good use by employing it in a cooperative workflow.\n",
    "To this end we gonna build a minimal cooperative machine learning using interface in this python notebook.\n",
    "Our user interface will consist of the following components:\n",
    "\n",
    "* (optional) A progressbar to keep to motivation up\n",
    "* A slider to set a high confidence threshold\n",
    "* A slider to set the mid confidence threshold\n",
    "* Some radio buttons to choose the label\n",
    "* A button to save the annotation and label and show the next image\n",
    "* A button to retrain our model\n",
    "* A button to use our model to predict our dataset\n",
    "\n",
    "The final our UI should look a like this:\n",
    "\n",
    "![img](https://hcm-lab.de/cloud/index.php/s/ak3txGXepnt9NxS/preview)\n",
    "\n",
    "The 'retrain' button should call the `train_loop()`  function from before to retrain the model on all labeled data.\n",
    "The 'predict' button should create a list of predictions for all unlabeled images.\n",
    "All predictions that are above the high confidence threshold, set by the respective slider, should be automatically accepted as correct label and copied to the respective folders in the training data folder.\n",
    "Additionally you should implement a garbage label to delete unfitting images.\n",
    "Potential reasons to consider an Image as garbage are if no Pokemon is visible, too many Pokemon are visible, non of the Pokemon we want to train are visible, the Imagefile is broken etc.\n",
    "When you are pressing the 'next' button the current image should be copied to the right folder in the training dataset, depending on the current value of the radio button.\n",
    "Afterwards the next image should be chosen from all predicted images, where the confidence is greater or equal than the value set by the mid_threshold slider.\n",
    "The current value of the radiobutton should then be set to the prediction for this respective image.\n",
    "Optionally you can also implement a progressbar to track your progress for you annotations.\n",
    "\n",
    "You can use the ipywidgets library to create the UI.\n",
    "You can find an IPython tutorial [here](https://towardsdatascience.com/interactive-controls-for-jupyter-notebooks-f5c94829aee6) and the api documentation [here](https://towardsdatascience.com/interactive-controls-for-jupyter-notebooks-f5c94829aee6).\n",
    "Note, that Pycharm might not play well with the the widgets in all scenarios. It's best to view them in the browser by visting: http://localhost:8888 after you started your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 13. Build UI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4. repeat(annotate, train, predict)\n",
    "After you are done creating the UI, we are now going to label the whole dataset together with our model.\n",
    "To this end use your model to predict and improve iteratively in the following manner:\n",
    "\n",
    "Set the high confidence slider to a value greater or equal than 0.95 and the mid confidence slider to at least 0.8\n",
    "\n",
    "Repeat 3 times:\n",
    "\n",
    "* Call automatic prediction\n",
    "* Check images that have been above the maximum confidence threshold manually by looking at the content of the respective folders. Make corrections if necessary.\n",
    "* Annotate remaining images that have been over the mid confidence score\n",
    "* Retrain you model\n",
    "\n",
    "Do you notice any change in the amount of images you have to annotate each time?\n",
    "\n",
    "Repeat till all data is annotated:\n",
    "\n",
    "* Call automatic prediction\n",
    "* Annotate remaining images that have been over the mid confidence score\n",
    "* Retrain you model\n",
    "* Adjust both confidence scores based on how much you trust your model\n",
    "\n",
    "Describe your subjective impression of the annotation process. Did you have the feeling, that the cooperative workflow is helpful?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
