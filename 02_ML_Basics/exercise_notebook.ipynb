{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Interactive Machine Learning - Exercise 02\n",
    "\n",
    "In this exercise we we will introduce you to the basics of machine learning with a focus on medical applications. \n",
    "\n",
    "\n",
    "The steps you are going to cover in this exercies are as follows:\n",
    "* Loading and preprocessing the data\n",
    "* Training and Evaluating a Support Vector Machine\n",
    "* Defining a Keras Model\n",
    "* Compiling a Keras Model\n",
    "* Fitting the Keras Model\n",
    "* Predicting and Evaluating with the Keras Model\n",
    "\n",
    "Please read each exercise carefully before you start coding! You will find a number in the comments before each step of coding you will do. Please refer to these numbers if you have any questions.\n",
    "\n",
    "\n",
    "## 0. Import the libraries\n",
    "The first step is to define the functions and classes we intend to use in this tutorial.\n",
    "We will use the NumPy library to load our dataset and we will use two classes from the Keras library to define our model.\n",
    "Further we use sklearn to accesss code for the Support Vector Machine and a helper file that comes with this notebook.\n",
    "The helper file contains the functions ```plot_confusion_matrix``` and ```plot_label_distribution```. \n",
    "\n",
    "The imports required are listed below.\n",
    "You can run this cell to import all the libraries for later usage. \n",
    "Keep in mind that you can import additional libraries at any time and that you do not need to use all the imports if you know another solution for a given task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "libraries successfully imported!\n"
     ]
    }
   ],
   "source": [
    "# hidding all warnings to not clutter the notebook\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# helper class to plot the confusion matrix\n",
    "from helper import plot_confusion_matrix, plot_label_distribution\n",
    "\n",
    "# numpy enables efficient numerical computations for common datastructures\n",
    "from numpy import loadtxt\n",
    "\n",
    "# a python library to help balancing datasets\n",
    "import imblearn\n",
    "\n",
    "# scikit-learn is a library for machine learning. we use it to train the support vector machine and evaluation\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# tensorflow/keras is a library for neural networks.\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "print(\"libraries successfully imported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data\n",
    "We can now load our dataset.  \n",
    "In this Exercise, we are going to use the Pima Indians onset of diabetes dataset. This is a standard machine learning dataset from the UCI Machine Learning repository. It describes patient medical record data for Pima Indians and whether they had an onset of diabetes within five years.\n",
    "As such, it is a binary classification problem (onset of diabetes as 1 or not as 0).  \n",
    "All of the input variables that describe each patient are numerical.\n",
    "This makes it easy to use directly with support vector machines and neural networks that expect numerical input and output values.\n",
    "\n",
    "The input data ist structured as a CSV-file where each row represents the data of one patient and each column a specific feature:\n",
    "1. Number of times pregnant\n",
    "2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "3. Diastolic blood pressure (mm Hg)\n",
    "4. Triceps skin fold thickness (mm)\n",
    "5. 2-Hour serum insulin (mu U/ml)\n",
    "6. Body mass index (weight in kg/(height in m)^2)\n",
    "7. Diabetes pedigree function\n",
    "8. Age (years)\n",
    "\n",
    "The last (9th) column contains the label. You will find the file under data/pima-indians-diabetes.csv and more information about the dataset in the readme.md .\n",
    "In the following code snippet you should write the code to load the data and and the labels into numpy arrays and subsequently scale the value of each feature so that the minimum of each feature in the dataset is 0 and the maximum is 1. \n",
    "\n",
    "Helpful links: \n",
    "* [Load text with numpy](https://numpy.org/doc/stable/reference/generated/numpy.loadtxt.html?highlight=numpy%20loadtxt#numpy.loadtxt)\n",
    "* [Normalization](https://en.wikipedia.org/wiki/Normalization_(statistics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 1. load the dataset\n",
    "dataset = loadtxt('data/pima-indians-diabetes.csv', delimiter=',')\n",
    "\n",
    "# 2. split into input (x) and output (y) variables\n",
    "x = dataset[:,:-1]\n",
    "y = dataset[:, -1]\n",
    "\n",
    "# 3. apply min-max feature scaling to bring input data between 0 and 1\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "x = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking that x data is indeed scaled and shapes of x and y to avoid possible missmatching or errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.35294118, 0.74371859, 0.59016393, ..., 0.50074516, 0.23441503,\n",
       "         0.48333333],\n",
       "        [0.05882353, 0.42713568, 0.54098361, ..., 0.39642325, 0.11656704,\n",
       "         0.16666667],\n",
       "        [0.47058824, 0.91959799, 0.52459016, ..., 0.34724292, 0.25362938,\n",
       "         0.18333333],\n",
       "        ...,\n",
       "        [0.29411765, 0.6080402 , 0.59016393, ..., 0.390462  , 0.07130658,\n",
       "         0.15      ],\n",
       "        [0.05882353, 0.63316583, 0.49180328, ..., 0.4485842 , 0.11571307,\n",
       "         0.43333333],\n",
       "        [0.05882353, 0.46733668, 0.57377049, ..., 0.45305514, 0.10119556,\n",
       "         0.03333333]]), (768, 8))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
       "        1., 0., 1.]), (768,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:20], y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now x should contain the normalized features, and y should contain the labels.\n",
    "In order to test how well our model works in later steps we now want to split our data in a train and a validation set.\n",
    "\n",
    "In order to do so, split x into x_train (the first 80% of your data) and x_val (the remaining 20% of your data),\n",
    "and repeat this for y (y_train and y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 4. split x and y into a 80 / 20 train and validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((614, 8), (154, 8), (614,), (154,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are almost ready to train our model. But before we do that let's have closer look at our training data. \n",
    "We have already learned that the distribution of the labels during training can have a huge impact on the final performance of our model.\n",
    "One way to tackle this hurdle is the application of over- and under-sampling. \n",
    "In the following will preprocess your data as follows: \n",
    " \n",
    "* First plot the label distribution of your current training data. To this end you can use ```plot_label_distribution(labels, classes=['No Diabetis', 'Diabetis'])``` function from the helper class.\n",
    "* Apply a resampling approach of your own choosing\n",
    "* Plot the label distribution of your current training data again to verify the results\n",
    "\n",
    "Helpful links:\n",
    "* [imblearn undersampling methods](https://imbalanced-learn.readthedocs.io/en/stable/api.html#module-imblearn.under_sampling)\n",
    "* [imblearn oversampling methods](https://imbalanced-learn.readthedocs.io/en/stable/api.html#module-imblearn.over_sampling)\n",
    "* [imblearn tutorial](https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5. plotting the label distribution for the training data\n",
    "plot_label_distribution(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking how many diabetis and non-diabetis instances we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset shape Counter({0.0: 401, 1.0: 213})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print('Train dataset shape %s' % Counter(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((426, 8), (426,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. apply a balancing algorithm of your choice (e.g. smote)\n",
    "smote = imblearn.under_sampling.RandomUnderSampler(random_state=42)\n",
    "\n",
    "X_train_bal, y_train_bal = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "X_train_bal.shape, y_train_bal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 7. plot the label distribution again\n",
    "plot_label_distribution(y_train_bal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Support Vector Machines\n",
    "Now we are done preparing our data. In this exercise we want to work with two different classification algorithms.\n",
    "The first one is a Support Vector Machine (SVM) based on the sklearn library.\n",
    "For this step, you will:\n",
    "\n",
    "* Create a SVM Classifier with a linear Kernel\n",
    "\n",
    "* Train your model using the ```fit()``` function on x_train and y_train\n",
    "\n",
    "* Predict the labels in ```y_pred``` for the Validation set ```x_val```\n",
    "\n",
    "Helpful links:\n",
    "* [Support Vector Machines with sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)\n",
    "* [Support Vector Machine tutorial on datacamp](https://www.datacamp.com/community/tutorials/svm-classification-scikit-learn-python)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=2, loss='hinge')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8. Create a svm Classifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm_clf = LinearSVC(loss='hinge', C=2)\n",
    "\n",
    "# 9. Train the model using the training sets\n",
    "svm_clf.fit(X_train_bal, y_train_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM classifier is trained and x_val is predicted\n"
     ]
    }
   ],
   "source": [
    "# 10. Predict the response for test dataset\n",
    "y_pred = svm_clf.predict(X_val)\n",
    "\n",
    "print(\"SVM classifier is trained and x_val is predicted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation:\n",
    "\n",
    "In order to evaluate the model a simple method is to print a few entries from the prediction set and to compare them with the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 entries from test data (y_val):  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0.\n",
      " 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0.\n",
      " 0. 0.]\n",
      "50 entries from predicted data (y_pred):  [0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0.\n",
      " 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0.\n",
      " 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# 11. summarize the first 50 cases\n",
    "print('50 entries from test data (y_val): ', y_val[:50])\n",
    "print('50 entries from predicted data (y_pred): ', y_pred[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to get some more meaningful information about the quality of your model you should use\n",
    "the sklearn function classification_report and plot a confusion matrix.\n",
    "\n",
    "In order to do so, you can call\n",
    "```plot_confusion_matrix(y_true, y_pred, class_names, title='Confusion Matrix', cmap=None, normalize=True, decimals=2)```\n",
    "from the file helper.py.\n",
    "\n",
    "Helpful links:\n",
    "* [classication_report description](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "class 0 - No Diabetes       0.82      0.71      0.76        99\n",
      "   class 1 - Diabetes       0.58      0.73      0.65        55\n",
      "\n",
      "             accuracy                           0.71       154\n",
      "            macro avg       0.70      0.72      0.70       154\n",
      "         weighted avg       0.74      0.71      0.72       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 12. Call sklearn's classification report - For your orientation: your model should reach an average recall (macro) of > 0.75\n",
    "target_names = ['class 0 - No Diabetes', 'class 1 - Diabetes']\n",
    "print(classification_report(y_val, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 13. Call plot_confusion_matrix to paint the confusion matrix\n",
    "plot_confusion_matrix(y_val, y_pred, classes=target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, you now have trained and evaluated a model that was trained with a Support Vector machine.\n",
    "That was easy right? Support Vector Machines have the advantage that they are fast, and don't need parameter tuning in most cases. So for many classification and regression tasks they do a decent job.\n",
    "\n",
    "But how do they perform compared to artifical neural neworks?\n",
    "\n",
    "In the next chapters we will repeat these last steps, but this time with an artifical neural network defined in Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Keras Model\n",
    "\n",
    "Models in Keras are defined as a sequence of layers. \n",
    "We create a Sequential model and one hidden layer and an output layer to it. \n",
    "The first thing to get right is to ensure the input layer has the right number of input features. This can be specified when creating the first layer with the input_dim argument and setting it to 8 for the 8 input variables. \n",
    "How do we know the number of layers and their types?  \n",
    "This is a very hard question. There are heuristics that we can use and often the best network structure is found through a process of trial and error experimentation (I explain more about this here). Generally, you need a network large enough to capture the structure of the problem. \n",
    "In this example, we will use a fully-connected network structure with two layers. \n",
    "Fully connected layers are defined using the Dense class. We can specify the number of neurons or nodes in the layer as the first argument, and specify the activation function using the activation argument. \n",
    "We will use the rectified linear unit activation function referred to as ReLU on the first two layers and the Sigmoid function in the output layer. \n",
    "It used to be the case that Sigmoid and Tanh activation functions were preferred for all layers. These days, better performance is achieved using the ReLU activation function. We use a sigmoid on the output layer to ensure our network output is between 0 and 1 and easy to map to either a probability of class 1 or snap to a hard classification of either class with a default threshold of 0.5. \n",
    "We can piece it all together by adding each layer:\n",
    "\n",
    "* The model expects rows of data with 8 variables (the input_dim=8 argument)\n",
    "* The hidden layer has 12 nodes and uses the relu activation function.\n",
    "* The output layer has one node and uses the sigmoid activation function.\n",
    "\n",
    "Helpful links: \n",
    "* [Keras guide to the sequential api](https://keras.io/getting-started/sequential-model-guide/)\n",
    "* [Activation Functions](https://keras.io/getting-started/sequential-model-guide/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 14. define the keras model\n",
    "model = Sequential([\n",
    "    Dense(8, activation = 'relu', input_shape = (8,)),\n",
    "    Dense(12, activation = 'relu'),\n",
    "    Dense(1, activation = 'sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compile Keras Model\n",
    "\n",
    "Now that the model is defined, we can compile it. \n",
    "Compiling the model uses the efficient numerical libraries under the covers (the so-called backend) such as Theano or TensorFlow. The backend automatically chooses the best way to represent the network for training and making predictions to run on your hardware, such as CPU or GPU or even distributed.\n",
    "When compiling, we must specify some additional properties required when training the network. Remember training a network means finding the best set of weights to map inputs to outputs in our dataset.  \n",
    "We must specify the loss function to use to evaluate a set of weights, the optimizer is used to search through different weights for the network and any optional metrics we would like to collect and report during training.\n",
    "In this case, we will use cross entropy as the loss argument. This loss is for a binary classification problems and is defined in Keras as *binary_crossentropy*. \n",
    "We will define the optimizer as the efficient stochastic gradient descent algorithm *adam*. This is a popular version of gradient descent because it automatically tunes itself and gives good results in a wide range of problems.\n",
    "Finally, because it is a classification problem, we will collect and report the classification accuracy, defined via the metrics argument.\n",
    "\n",
    "Helpful links: \n",
    "* [How to Choose Loss Functions When Training Deep Learning Neural Networks](https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/)\n",
    "* [Gentle Introduction to the Adam Optimization Algorithm for Deep Learning](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 193\n",
      "Trainable params: 193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 15. compile the keras model\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",\n",
    "                 metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fit Keras Model\n",
    "We have defined our model and compiled it ready for efficient computation.\n",
    "Now it is time to execute the model on some data.\n",
    "We can train or fit our model on our loaded data by calling the ```fit()```  function on the model.\n",
    "Training occurs over epochs and each epoch is split into batches.\n",
    "Epoch: One pass through all of the rows in the training dataset.\n",
    "Batch: One or more samples considered by the model within an epoch before weights are updated.\n",
    "One epoch is comprised of one or more batches, based on the chosen batch size and the model is fit for many epochs.\n",
    "What is the Difference Between a Batch and an Epoch in a Neural Network?\n",
    "The training process will run for a fixed number of iterations through the dataset called epochs, that we must specify using the epochs argument. We must also set the number of dataset rows that are considered before the model weights are updated within each epoch, called the batch size and set using the batch_size argument.  \n",
    "For this problem, we will run for a small number of epochs (150) and use a relatively small batch size of 10.\n",
    "These configurations can be chosen experimentally by trial and error. We want to train the model enough so that it learns a good (or good enough) mapping of rows of input data to the output classification. The model will always have some error, but the amount of error will level out after some point for a given model configuration. This is called model convergence.\n",
    "\n",
    "Helpful links:\n",
    "*  [Difference between a batch and an epoch](https://machinelearningmastery.com/difference-between-a-batch-and-an-epoch/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 614 samples, validate on 154 samples\n",
      "Epoch 1/150\n",
      "614/614 [==============================] - 0s 615us/sample - loss: 0.6938 - accuracy: 0.4984 - val_loss: 0.6807 - val_accuracy: 0.6429\n",
      "Epoch 2/150\n",
      "614/614 [==============================] - 0s 107us/sample - loss: 0.6717 - accuracy: 0.6531 - val_loss: 0.6705 - val_accuracy: 0.6429\n",
      "Epoch 3/150\n",
      "614/614 [==============================] - 0s 121us/sample - loss: 0.6619 - accuracy: 0.6531 - val_loss: 0.6641 - val_accuracy: 0.6429\n",
      "Epoch 4/150\n",
      "614/614 [==============================] - 0s 128us/sample - loss: 0.6560 - accuracy: 0.6531 - val_loss: 0.6601 - val_accuracy: 0.6429\n",
      "Epoch 5/150\n",
      "614/614 [==============================] - 0s 120us/sample - loss: 0.6525 - accuracy: 0.6531 - val_loss: 0.6570 - val_accuracy: 0.6429\n",
      "Epoch 6/150\n",
      "614/614 [==============================] - 0s 143us/sample - loss: 0.6495 - accuracy: 0.6531 - val_loss: 0.6533 - val_accuracy: 0.6429\n",
      "Epoch 7/150\n",
      "614/614 [==============================] - 0s 123us/sample - loss: 0.6466 - accuracy: 0.6531 - val_loss: 0.6497 - val_accuracy: 0.6429\n",
      "Epoch 8/150\n",
      "614/614 [==============================] - 0s 131us/sample - loss: 0.6436 - accuracy: 0.6531 - val_loss: 0.6448 - val_accuracy: 0.6429\n",
      "Epoch 9/150\n",
      "614/614 [==============================] - 0s 125us/sample - loss: 0.6394 - accuracy: 0.6531 - val_loss: 0.6400 - val_accuracy: 0.6429\n",
      "Epoch 10/150\n",
      "614/614 [==============================] - 0s 124us/sample - loss: 0.6351 - accuracy: 0.6531 - val_loss: 0.6347 - val_accuracy: 0.6429\n",
      "Epoch 11/150\n",
      "614/614 [==============================] - 0s 145us/sample - loss: 0.6303 - accuracy: 0.6531 - val_loss: 0.6291 - val_accuracy: 0.6429\n",
      "Epoch 12/150\n",
      "614/614 [==============================] - 0s 129us/sample - loss: 0.6251 - accuracy: 0.6531 - val_loss: 0.6233 - val_accuracy: 0.6429\n",
      "Epoch 13/150\n",
      "614/614 [==============================] - 0s 127us/sample - loss: 0.6202 - accuracy: 0.6564 - val_loss: 0.6163 - val_accuracy: 0.6623\n",
      "Epoch 14/150\n",
      "614/614 [==============================] - 0s 133us/sample - loss: 0.6146 - accuracy: 0.6661 - val_loss: 0.6103 - val_accuracy: 0.6753\n",
      "Epoch 15/150\n",
      "614/614 [==============================] - 0s 130us/sample - loss: 0.6083 - accuracy: 0.6792 - val_loss: 0.6033 - val_accuracy: 0.6753\n",
      "Epoch 16/150\n",
      "614/614 [==============================] - 0s 129us/sample - loss: 0.6026 - accuracy: 0.6710 - val_loss: 0.5971 - val_accuracy: 0.6688\n",
      "Epoch 17/150\n",
      "614/614 [==============================] - 0s 129us/sample - loss: 0.5969 - accuracy: 0.6808 - val_loss: 0.5912 - val_accuracy: 0.6818\n",
      "Epoch 18/150\n",
      "614/614 [==============================] - 0s 128us/sample - loss: 0.5914 - accuracy: 0.6922 - val_loss: 0.5854 - val_accuracy: 0.7078\n",
      "Epoch 19/150\n",
      "614/614 [==============================] - 0s 151us/sample - loss: 0.5870 - accuracy: 0.7085 - val_loss: 0.5796 - val_accuracy: 0.7013\n",
      "Epoch 20/150\n",
      "614/614 [==============================] - 0s 132us/sample - loss: 0.5814 - accuracy: 0.7117 - val_loss: 0.5744 - val_accuracy: 0.7078\n",
      "Epoch 21/150\n",
      "614/614 [==============================] - 0s 130us/sample - loss: 0.5755 - accuracy: 0.7036 - val_loss: 0.5698 - val_accuracy: 0.7338\n",
      "Epoch 22/150\n",
      "614/614 [==============================] - 0s 130us/sample - loss: 0.5711 - accuracy: 0.7166 - val_loss: 0.5646 - val_accuracy: 0.7597\n",
      "Epoch 23/150\n",
      "614/614 [==============================] - 0s 130us/sample - loss: 0.5663 - accuracy: 0.7248 - val_loss: 0.5582 - val_accuracy: 0.7403\n",
      "Epoch 24/150\n",
      "614/614 [==============================] - 0s 157us/sample - loss: 0.5620 - accuracy: 0.7280 - val_loss: 0.5541 - val_accuracy: 0.7727\n",
      "Epoch 25/150\n",
      "614/614 [==============================] - 0s 135us/sample - loss: 0.5567 - accuracy: 0.7248 - val_loss: 0.5499 - val_accuracy: 0.7857\n",
      "Epoch 26/150\n",
      "614/614 [==============================] - 0s 127us/sample - loss: 0.5521 - accuracy: 0.7296 - val_loss: 0.5458 - val_accuracy: 0.7792\n",
      "Epoch 27/150\n",
      "614/614 [==============================] - 0s 120us/sample - loss: 0.5474 - accuracy: 0.7296 - val_loss: 0.5413 - val_accuracy: 0.7792\n",
      "Epoch 28/150\n",
      "614/614 [==============================] - 0s 123us/sample - loss: 0.5432 - accuracy: 0.7345 - val_loss: 0.5362 - val_accuracy: 0.7792\n",
      "Epoch 29/150\n",
      "614/614 [==============================] - 0s 129us/sample - loss: 0.5387 - accuracy: 0.7248 - val_loss: 0.5330 - val_accuracy: 0.7857\n",
      "Epoch 30/150\n",
      "614/614 [==============================] - 0s 124us/sample - loss: 0.5353 - accuracy: 0.7378 - val_loss: 0.5293 - val_accuracy: 0.7792\n",
      "Epoch 31/150\n",
      "614/614 [==============================] - 0s 127us/sample - loss: 0.5319 - accuracy: 0.7280 - val_loss: 0.5265 - val_accuracy: 0.7922\n",
      "Epoch 32/150\n",
      "614/614 [==============================] - 0s 127us/sample - loss: 0.5292 - accuracy: 0.7394 - val_loss: 0.5227 - val_accuracy: 0.7857\n",
      "Epoch 33/150\n",
      "614/614 [==============================] - 0s 128us/sample - loss: 0.5258 - accuracy: 0.7427 - val_loss: 0.5200 - val_accuracy: 0.7857\n",
      "Epoch 34/150\n",
      "614/614 [==============================] - 0s 123us/sample - loss: 0.5219 - accuracy: 0.7329 - val_loss: 0.5178 - val_accuracy: 0.7857\n",
      "Epoch 35/150\n",
      "614/614 [==============================] - 0s 129us/sample - loss: 0.5193 - accuracy: 0.7410 - val_loss: 0.5151 - val_accuracy: 0.7792\n",
      "Epoch 36/150\n",
      "614/614 [==============================] - 0s 129us/sample - loss: 0.5163 - accuracy: 0.7492 - val_loss: 0.5137 - val_accuracy: 0.7792\n",
      "Epoch 37/150\n",
      "614/614 [==============================] - 0s 123us/sample - loss: 0.5136 - accuracy: 0.7394 - val_loss: 0.5116 - val_accuracy: 0.7922\n",
      "Epoch 38/150\n",
      "614/614 [==============================] - 0s 118us/sample - loss: 0.5122 - accuracy: 0.7394 - val_loss: 0.5123 - val_accuracy: 0.7922\n",
      "Epoch 39/150\n",
      "614/614 [==============================] - 0s 112us/sample - loss: 0.5101 - accuracy: 0.7476 - val_loss: 0.5079 - val_accuracy: 0.7792\n",
      "Epoch 40/150\n",
      "614/614 [==============================] - 0s 115us/sample - loss: 0.5079 - accuracy: 0.7524 - val_loss: 0.5076 - val_accuracy: 0.7857\n",
      "Epoch 41/150\n",
      "614/614 [==============================] - 0s 108us/sample - loss: 0.5048 - accuracy: 0.7476 - val_loss: 0.5061 - val_accuracy: 0.7792\n",
      "Epoch 42/150\n",
      "614/614 [==============================] - 0s 110us/sample - loss: 0.5035 - accuracy: 0.7524 - val_loss: 0.5064 - val_accuracy: 0.7792\n",
      "Epoch 43/150\n",
      "614/614 [==============================] - 0s 110us/sample - loss: 0.5009 - accuracy: 0.7541 - val_loss: 0.5041 - val_accuracy: 0.7857\n",
      "Epoch 44/150\n",
      "614/614 [==============================] - 0s 115us/sample - loss: 0.5012 - accuracy: 0.7573 - val_loss: 0.5022 - val_accuracy: 0.7857\n",
      "Epoch 45/150\n",
      "614/614 [==============================] - 0s 115us/sample - loss: 0.4963 - accuracy: 0.7590 - val_loss: 0.5026 - val_accuracy: 0.7922\n",
      "Epoch 46/150\n",
      "614/614 [==============================] - 0s 111us/sample - loss: 0.4951 - accuracy: 0.7622 - val_loss: 0.5024 - val_accuracy: 0.7922\n",
      "Epoch 47/150\n",
      "614/614 [==============================] - 0s 104us/sample - loss: 0.4930 - accuracy: 0.7590 - val_loss: 0.4994 - val_accuracy: 0.7987\n",
      "Epoch 48/150\n",
      "614/614 [==============================] - 0s 97us/sample - loss: 0.4934 - accuracy: 0.7573 - val_loss: 0.4981 - val_accuracy: 0.8052\n",
      "Epoch 49/150\n",
      "614/614 [==============================] - 0s 93us/sample - loss: 0.4904 - accuracy: 0.7655 - val_loss: 0.4990 - val_accuracy: 0.7987\n",
      "Epoch 50/150\n",
      "614/614 [==============================] - 0s 91us/sample - loss: 0.4880 - accuracy: 0.7606 - val_loss: 0.4995 - val_accuracy: 0.7922\n",
      "Epoch 51/150\n",
      "614/614 [==============================] - 0s 93us/sample - loss: 0.4882 - accuracy: 0.7622 - val_loss: 0.4966 - val_accuracy: 0.7922\n",
      "Epoch 52/150\n",
      "614/614 [==============================] - 0s 92us/sample - loss: 0.4857 - accuracy: 0.7671 - val_loss: 0.4974 - val_accuracy: 0.7987\n",
      "Epoch 53/150\n",
      "614/614 [==============================] - 0s 92us/sample - loss: 0.4846 - accuracy: 0.7704 - val_loss: 0.4992 - val_accuracy: 0.7987\n",
      "Epoch 54/150\n",
      "614/614 [==============================] - 0s 98us/sample - loss: 0.4825 - accuracy: 0.7687 - val_loss: 0.4989 - val_accuracy: 0.7857\n",
      "Epoch 55/150\n",
      "614/614 [==============================] - 0s 92us/sample - loss: 0.4816 - accuracy: 0.7704 - val_loss: 0.4956 - val_accuracy: 0.8052\n",
      "Epoch 56/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614/614 [==============================] - 0s 91us/sample - loss: 0.4793 - accuracy: 0.7769 - val_loss: 0.4943 - val_accuracy: 0.8052\n",
      "Epoch 57/150\n",
      "614/614 [==============================] - 0s 93us/sample - loss: 0.4795 - accuracy: 0.7752 - val_loss: 0.4941 - val_accuracy: 0.7987\n",
      "Epoch 58/150\n",
      "614/614 [==============================] - 0s 101us/sample - loss: 0.4779 - accuracy: 0.7687 - val_loss: 0.4942 - val_accuracy: 0.7987\n",
      "Epoch 59/150\n",
      "614/614 [==============================] - 0s 96us/sample - loss: 0.4763 - accuracy: 0.7752 - val_loss: 0.4924 - val_accuracy: 0.8117\n",
      "Epoch 60/150\n",
      "614/614 [==============================] - 0s 98us/sample - loss: 0.4762 - accuracy: 0.7736 - val_loss: 0.4941 - val_accuracy: 0.8052\n",
      "Epoch 61/150\n",
      "614/614 [==============================] - 0s 103us/sample - loss: 0.4753 - accuracy: 0.7720 - val_loss: 0.4946 - val_accuracy: 0.8052\n",
      "Epoch 62/150\n",
      "614/614 [==============================] - 0s 97us/sample - loss: 0.4733 - accuracy: 0.7752 - val_loss: 0.4955 - val_accuracy: 0.8052\n",
      "Epoch 63/150\n",
      "614/614 [==============================] - 0s 92us/sample - loss: 0.4723 - accuracy: 0.7769 - val_loss: 0.4949 - val_accuracy: 0.7987\n",
      "Epoch 64/150\n",
      "614/614 [==============================] - 0s 91us/sample - loss: 0.4714 - accuracy: 0.7752 - val_loss: 0.4943 - val_accuracy: 0.8117\n",
      "Epoch 65/150\n",
      "614/614 [==============================] - 0s 92us/sample - loss: 0.4697 - accuracy: 0.7736 - val_loss: 0.4949 - val_accuracy: 0.7987\n",
      "Epoch 66/150\n",
      "614/614 [==============================] - 0s 94us/sample - loss: 0.4693 - accuracy: 0.7752 - val_loss: 0.4937 - val_accuracy: 0.8117\n",
      "Epoch 67/150\n",
      "614/614 [==============================] - 0s 98us/sample - loss: 0.4684 - accuracy: 0.7785 - val_loss: 0.4939 - val_accuracy: 0.8052\n",
      "Epoch 68/150\n",
      "614/614 [==============================] - 0s 92us/sample - loss: 0.4670 - accuracy: 0.7769 - val_loss: 0.5004 - val_accuracy: 0.7987\n",
      "Epoch 69/150\n",
      "614/614 [==============================] - 0s 92us/sample - loss: 0.4674 - accuracy: 0.7704 - val_loss: 0.4953 - val_accuracy: 0.8117\n",
      "Epoch 70/150\n",
      "614/614 [==============================] - 0s 97us/sample - loss: 0.4647 - accuracy: 0.7818 - val_loss: 0.4992 - val_accuracy: 0.8052\n",
      "Epoch 71/150\n",
      "614/614 [==============================] - 0s 95us/sample - loss: 0.4644 - accuracy: 0.7769 - val_loss: 0.4953 - val_accuracy: 0.7987\n",
      "Epoch 72/150\n",
      "614/614 [==============================] - 0s 97us/sample - loss: 0.4664 - accuracy: 0.7720 - val_loss: 0.4953 - val_accuracy: 0.7987\n",
      "Epoch 73/150\n",
      "614/614 [==============================] - 0s 98us/sample - loss: 0.4623 - accuracy: 0.7752 - val_loss: 0.5000 - val_accuracy: 0.8052\n",
      "Epoch 74/150\n",
      "614/614 [==============================] - 0s 92us/sample - loss: 0.4643 - accuracy: 0.7704 - val_loss: 0.4980 - val_accuracy: 0.7922\n",
      "Epoch 75/150\n",
      "614/614 [==============================] - 0s 94us/sample - loss: 0.4612 - accuracy: 0.7801 - val_loss: 0.4981 - val_accuracy: 0.7857\n",
      "Epoch 76/150\n",
      "614/614 [==============================] - 0s 94us/sample - loss: 0.4617 - accuracy: 0.7687 - val_loss: 0.4996 - val_accuracy: 0.8052\n",
      "Epoch 77/150\n",
      "614/614 [==============================] - 0s 95us/sample - loss: 0.4599 - accuracy: 0.7818 - val_loss: 0.4975 - val_accuracy: 0.8052\n",
      "Epoch 78/150\n",
      "614/614 [==============================] - 0s 97us/sample - loss: 0.4589 - accuracy: 0.7801 - val_loss: 0.4986 - val_accuracy: 0.7987\n",
      "Epoch 79/150\n",
      "614/614 [==============================] - 0s 90us/sample - loss: 0.4597 - accuracy: 0.7736 - val_loss: 0.4985 - val_accuracy: 0.7987\n",
      "Epoch 80/150\n",
      "614/614 [==============================] - 0s 101us/sample - loss: 0.4591 - accuracy: 0.7785 - val_loss: 0.4995 - val_accuracy: 0.7922\n",
      "Epoch 81/150\n",
      "614/614 [==============================] - 0s 92us/sample - loss: 0.4577 - accuracy: 0.7785 - val_loss: 0.5041 - val_accuracy: 0.7922\n",
      "Epoch 82/150\n",
      "614/614 [==============================] - 0s 93us/sample - loss: 0.4595 - accuracy: 0.7785 - val_loss: 0.5041 - val_accuracy: 0.7987\n",
      "Epoch 83/150\n",
      "614/614 [==============================] - 0s 98us/sample - loss: 0.4589 - accuracy: 0.7818 - val_loss: 0.5027 - val_accuracy: 0.7987\n",
      "Epoch 84/150\n",
      "614/614 [==============================] - 0s 97us/sample - loss: 0.4570 - accuracy: 0.7671 - val_loss: 0.4996 - val_accuracy: 0.7987\n",
      "Epoch 85/150\n",
      "614/614 [==============================] - 0s 95us/sample - loss: 0.4565 - accuracy: 0.7801 - val_loss: 0.5085 - val_accuracy: 0.7857\n",
      "Epoch 86/150\n",
      "614/614 [==============================] - 0s 98us/sample - loss: 0.4561 - accuracy: 0.7769 - val_loss: 0.5043 - val_accuracy: 0.7922\n",
      "Epoch 87/150\n",
      "614/614 [==============================] - 0s 95us/sample - loss: 0.4554 - accuracy: 0.7769 - val_loss: 0.5026 - val_accuracy: 0.7922\n",
      "Epoch 88/150\n",
      "614/614 [==============================] - 0s 92us/sample - loss: 0.4539 - accuracy: 0.7834 - val_loss: 0.5016 - val_accuracy: 0.7987\n",
      "Epoch 89/150\n",
      "614/614 [==============================] - 0s 97us/sample - loss: 0.4556 - accuracy: 0.7720 - val_loss: 0.5021 - val_accuracy: 0.7922\n",
      "Epoch 90/150\n",
      "614/614 [==============================] - 0s 97us/sample - loss: 0.4539 - accuracy: 0.7769 - val_loss: 0.5082 - val_accuracy: 0.7922\n",
      "Epoch 91/150\n",
      "614/614 [==============================] - 0s 92us/sample - loss: 0.4531 - accuracy: 0.7785 - val_loss: 0.5049 - val_accuracy: 0.7922\n",
      "Epoch 92/150\n",
      "614/614 [==============================] - 0s 92us/sample - loss: 0.4522 - accuracy: 0.7736 - val_loss: 0.5063 - val_accuracy: 0.7922\n",
      "Epoch 93/150\n",
      "614/614 [==============================] - 0s 98us/sample - loss: 0.4513 - accuracy: 0.7752 - val_loss: 0.5075 - val_accuracy: 0.7987\n",
      "Epoch 94/150\n",
      "614/614 [==============================] - 0s 91us/sample - loss: 0.4519 - accuracy: 0.7769 - val_loss: 0.5087 - val_accuracy: 0.7792\n",
      "Epoch 95/150\n",
      "614/614 [==============================] - 0s 96us/sample - loss: 0.4516 - accuracy: 0.7671 - val_loss: 0.5059 - val_accuracy: 0.7857\n",
      "Epoch 96/150\n",
      "614/614 [==============================] - 0s 91us/sample - loss: 0.4523 - accuracy: 0.7671 - val_loss: 0.5061 - val_accuracy: 0.7922\n",
      "Epoch 97/150\n",
      "614/614 [==============================] - 0s 93us/sample - loss: 0.4518 - accuracy: 0.7801 - val_loss: 0.5096 - val_accuracy: 0.7792\n",
      "Epoch 98/150\n",
      "614/614 [==============================] - 0s 97us/sample - loss: 0.4527 - accuracy: 0.7801 - val_loss: 0.5078 - val_accuracy: 0.7922\n",
      "Epoch 99/150\n",
      "614/614 [==============================] - 0s 96us/sample - loss: 0.4503 - accuracy: 0.7818 - val_loss: 0.5095 - val_accuracy: 0.8052\n",
      "Epoch 100/150\n",
      "614/614 [==============================] - 0s 92us/sample - loss: 0.4503 - accuracy: 0.7769 - val_loss: 0.5086 - val_accuracy: 0.7857\n",
      "Epoch 101/150\n",
      "614/614 [==============================] - 0s 94us/sample - loss: 0.4503 - accuracy: 0.7752 - val_loss: 0.5075 - val_accuracy: 0.7987\n",
      "Epoch 102/150\n",
      "614/614 [==============================] - 0s 94us/sample - loss: 0.4489 - accuracy: 0.7769 - val_loss: 0.5096 - val_accuracy: 0.7792\n",
      "Epoch 103/150\n",
      "614/614 [==============================] - 0s 91us/sample - loss: 0.4482 - accuracy: 0.7818 - val_loss: 0.5104 - val_accuracy: 0.7792\n",
      "Epoch 104/150\n",
      "614/614 [==============================] - 0s 93us/sample - loss: 0.4497 - accuracy: 0.7785 - val_loss: 0.5087 - val_accuracy: 0.7922\n",
      "Epoch 105/150\n",
      "614/614 [==============================] - 0s 97us/sample - loss: 0.4489 - accuracy: 0.7801 - val_loss: 0.5097 - val_accuracy: 0.7792\n",
      "Epoch 106/150\n",
      "614/614 [==============================] - 0s 94us/sample - loss: 0.4478 - accuracy: 0.7785 - val_loss: 0.5116 - val_accuracy: 0.7792\n",
      "Epoch 107/150\n",
      "614/614 [==============================] - 0s 97us/sample - loss: 0.4468 - accuracy: 0.7752 - val_loss: 0.5144 - val_accuracy: 0.7792\n",
      "Epoch 108/150\n",
      "614/614 [==============================] - 0s 97us/sample - loss: 0.4497 - accuracy: 0.7850 - val_loss: 0.5096 - val_accuracy: 0.7857\n",
      "Epoch 109/150\n",
      "614/614 [==============================] - 0s 95us/sample - loss: 0.4476 - accuracy: 0.7785 - val_loss: 0.5148 - val_accuracy: 0.7662\n",
      "Epoch 110/150\n",
      "614/614 [==============================] - 0s 91us/sample - loss: 0.4484 - accuracy: 0.7736 - val_loss: 0.5180 - val_accuracy: 0.7662\n",
      "Epoch 111/150\n",
      "614/614 [==============================] - 0s 93us/sample - loss: 0.4485 - accuracy: 0.7834 - val_loss: 0.5141 - val_accuracy: 0.7792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/150\n",
      "614/614 [==============================] - 0s 109us/sample - loss: 0.4467 - accuracy: 0.7818 - val_loss: 0.5131 - val_accuracy: 0.7727\n",
      "Epoch 113/150\n",
      "614/614 [==============================] - 0s 94us/sample - loss: 0.4470 - accuracy: 0.7801 - val_loss: 0.5120 - val_accuracy: 0.7857\n",
      "Epoch 114/150\n",
      "614/614 [==============================] - 0s 96us/sample - loss: 0.4479 - accuracy: 0.7785 - val_loss: 0.5124 - val_accuracy: 0.7922\n",
      "Epoch 115/150\n",
      "614/614 [==============================] - 0s 97us/sample - loss: 0.4464 - accuracy: 0.7818 - val_loss: 0.5112 - val_accuracy: 0.7792\n",
      "Epoch 116/150\n",
      "614/614 [==============================] - 0s 96us/sample - loss: 0.4460 - accuracy: 0.7769 - val_loss: 0.5200 - val_accuracy: 0.7597\n",
      "Epoch 117/150\n",
      "614/614 [==============================] - 0s 95us/sample - loss: 0.4469 - accuracy: 0.7720 - val_loss: 0.5177 - val_accuracy: 0.7662\n",
      "Epoch 118/150\n",
      "614/614 [==============================] - 0s 96us/sample - loss: 0.4470 - accuracy: 0.7834 - val_loss: 0.5132 - val_accuracy: 0.7857\n",
      "Epoch 119/150\n",
      "614/614 [==============================] - 0s 98us/sample - loss: 0.4460 - accuracy: 0.7769 - val_loss: 0.5114 - val_accuracy: 0.7857\n",
      "Epoch 120/150\n",
      "614/614 [==============================] - 0s 98us/sample - loss: 0.4452 - accuracy: 0.7801 - val_loss: 0.5167 - val_accuracy: 0.7662\n",
      "Epoch 121/150\n",
      "614/614 [==============================] - 0s 92us/sample - loss: 0.4453 - accuracy: 0.7720 - val_loss: 0.5195 - val_accuracy: 0.7662\n",
      "Epoch 122/150\n",
      "614/614 [==============================] - 0s 97us/sample - loss: 0.4458 - accuracy: 0.7769 - val_loss: 0.5135 - val_accuracy: 0.7727\n",
      "Epoch 123/150\n",
      "614/614 [==============================] - 0s 93us/sample - loss: 0.4450 - accuracy: 0.7866 - val_loss: 0.5151 - val_accuracy: 0.7792\n",
      "Epoch 124/150\n",
      "614/614 [==============================] - 0s 106us/sample - loss: 0.4448 - accuracy: 0.7818 - val_loss: 0.5195 - val_accuracy: 0.7597\n",
      "Epoch 125/150\n",
      "614/614 [==============================] - 0s 94us/sample - loss: 0.4441 - accuracy: 0.7752 - val_loss: 0.5180 - val_accuracy: 0.7597\n",
      "Epoch 126/150\n",
      "614/614 [==============================] - 0s 96us/sample - loss: 0.4441 - accuracy: 0.7785 - val_loss: 0.5183 - val_accuracy: 0.8052\n",
      "Epoch 127/150\n",
      "614/614 [==============================] - 0s 103us/sample - loss: 0.4467 - accuracy: 0.7736 - val_loss: 0.5153 - val_accuracy: 0.7857\n",
      "Epoch 128/150\n",
      "614/614 [==============================] - 0s 93us/sample - loss: 0.4434 - accuracy: 0.7769 - val_loss: 0.5160 - val_accuracy: 0.7792\n",
      "Epoch 129/150\n",
      "614/614 [==============================] - 0s 98us/sample - loss: 0.4455 - accuracy: 0.7801 - val_loss: 0.5170 - val_accuracy: 0.7792\n",
      "Epoch 130/150\n",
      "614/614 [==============================] - 0s 100us/sample - loss: 0.4437 - accuracy: 0.7769 - val_loss: 0.5149 - val_accuracy: 0.7857\n",
      "Epoch 131/150\n",
      "614/614 [==============================] - 0s 93us/sample - loss: 0.4446 - accuracy: 0.7785 - val_loss: 0.5158 - val_accuracy: 0.7857\n",
      "Epoch 132/150\n",
      "614/614 [==============================] - 0s 98us/sample - loss: 0.4443 - accuracy: 0.7866 - val_loss: 0.5166 - val_accuracy: 0.7922\n",
      "Epoch 133/150\n",
      "614/614 [==============================] - 0s 93us/sample - loss: 0.4463 - accuracy: 0.7866 - val_loss: 0.5170 - val_accuracy: 0.7857\n",
      "Epoch 134/150\n",
      "614/614 [==============================] - 0s 92us/sample - loss: 0.4435 - accuracy: 0.7801 - val_loss: 0.5169 - val_accuracy: 0.7727\n",
      "Epoch 135/150\n",
      "614/614 [==============================] - 0s 93us/sample - loss: 0.4433 - accuracy: 0.7883 - val_loss: 0.5184 - val_accuracy: 0.7857\n",
      "Epoch 136/150\n",
      "614/614 [==============================] - 0s 98us/sample - loss: 0.4430 - accuracy: 0.7769 - val_loss: 0.5188 - val_accuracy: 0.7727\n",
      "Epoch 137/150\n",
      "614/614 [==============================] - 0s 95us/sample - loss: 0.4437 - accuracy: 0.7834 - val_loss: 0.5179 - val_accuracy: 0.7727\n",
      "Epoch 138/150\n",
      "614/614 [==============================] - 0s 93us/sample - loss: 0.4424 - accuracy: 0.7785 - val_loss: 0.5205 - val_accuracy: 0.7597\n",
      "Epoch 139/150\n",
      "614/614 [==============================] - 0s 92us/sample - loss: 0.4412 - accuracy: 0.7704 - val_loss: 0.5185 - val_accuracy: 0.7792\n",
      "Epoch 140/150\n",
      "614/614 [==============================] - 0s 91us/sample - loss: 0.4423 - accuracy: 0.7736 - val_loss: 0.5179 - val_accuracy: 0.7792\n",
      "Epoch 141/150\n",
      "614/614 [==============================] - 0s 97us/sample - loss: 0.4427 - accuracy: 0.7866 - val_loss: 0.5185 - val_accuracy: 0.7857\n",
      "Epoch 142/150\n",
      "614/614 [==============================] - 0s 91us/sample - loss: 0.4454 - accuracy: 0.7866 - val_loss: 0.5190 - val_accuracy: 0.7857\n",
      "Epoch 143/150\n",
      "614/614 [==============================] - 0s 95us/sample - loss: 0.4411 - accuracy: 0.7769 - val_loss: 0.5208 - val_accuracy: 0.7662\n",
      "Epoch 144/150\n",
      "614/614 [==============================] - 0s 97us/sample - loss: 0.4415 - accuracy: 0.7801 - val_loss: 0.5192 - val_accuracy: 0.7727\n",
      "Epoch 145/150\n",
      "614/614 [==============================] - 0s 95us/sample - loss: 0.4440 - accuracy: 0.7785 - val_loss: 0.5170 - val_accuracy: 0.7792\n",
      "Epoch 146/150\n",
      "614/614 [==============================] - 0s 93us/sample - loss: 0.4415 - accuracy: 0.7834 - val_loss: 0.5187 - val_accuracy: 0.7792\n",
      "Epoch 147/150\n",
      "614/614 [==============================] - 0s 96us/sample - loss: 0.4399 - accuracy: 0.7785 - val_loss: 0.5200 - val_accuracy: 0.7662\n",
      "Epoch 148/150\n",
      "614/614 [==============================] - 0s 91us/sample - loss: 0.4421 - accuracy: 0.7801 - val_loss: 0.5198 - val_accuracy: 0.7792\n",
      "Epoch 149/150\n",
      "614/614 [==============================] - 0s 92us/sample - loss: 0.4422 - accuracy: 0.7769 - val_loss: 0.5215 - val_accuracy: 0.7597\n",
      "Epoch 150/150\n",
      "614/614 [==============================] - 0s 91us/sample - loss: 0.4428 - accuracy: 0.7785 - val_loss: 0.5187 - val_accuracy: 0.7792\n"
     ]
    }
   ],
   "source": [
    "# 16. fit the keras model on the dataset\n",
    "history = model.fit(X_train, y_train, batch_size=10, epochs=150, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.Make Predictions\n",
    "\n",
    "After I train my model, how can I use it to make predictions on new data? - Great question.\n",
    "We can adapt the above example and use it to generate predictions on the training dataset, pretending it is a new dataset we have not seen before.\n",
    "Making predictions is as easy as calling the ```predict()``` function on the model. We are using a sigmoid activation function on the output layer, so the predictions will be a probability in the range between 0 and 1. We can easily convert them into a crisp binary prediction for this classification task by rounding them.\n",
    "\n",
    "Helpful links: \n",
    "* [Keras predict](https://keras.io/models/model/#predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154/154 [==============================] - 0s 34us/sample - loss: 0.5187 - accuracy: 0.7792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5187185143495535, 0.77922076]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3610463 ],\n",
       "       [0.12004365],\n",
       "       [0.08280127],\n",
       "       [0.21682347],\n",
       "       [0.5582764 ],\n",
       "       [0.5441078 ],\n",
       "       [0.03676458],\n",
       "       [0.4470532 ],\n",
       "       [0.67833585],\n",
       "       [0.35956383]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 17. make probability predictions with the model\n",
    "y_pred = model.predict(X_val)\n",
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 18. use the round function to round each entry of y_pred to either 0.0 or 1.0\n",
    "y_pred.round()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.Evaluation\n",
    "Great, we are almost done now:\n",
    "Exactly as in the Support Vector Machine example, we now want to print the first 50 entries from the prediction set and to compare them with the validation set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 entries from test data (y_val):  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0.\n",
      " 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0.\n",
      " 0. 0.]\n",
      "50 entries from predicted data (y_pred):  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "# 19. summarize the first 50 cases\n",
    "print('50 entries from test data (y_val): ', y_val[:50])\n",
    "print('50 entries from predicted data (y_pred): ', y_pred[:50].round())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, once again,  we want to use sklearn's classification report, as well as the plot_confusion_matrix function in order to print the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "class 0 - No Diabetes       0.80      0.88      0.84        99\n",
      "   class 1 - Diabetes       0.73      0.60      0.66        55\n",
      "\n",
      "             accuracy                           0.78       154\n",
      "            macro avg       0.77      0.74      0.75       154\n",
      "         weighted avg       0.78      0.78      0.77       154\n",
      "\n",
      "Normalized confusion matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 20. Call sklearn's classification report\n",
    "print(classification_report(y_val, y_pred.round(), target_names=target_names))\n",
    "\n",
    "# 21. Call plot_confusion_matrix to paint the confusion matrix - For your orientation: your model should reach an average recall (macro) of > 0.75\n",
    "plot_confusion_matrix(y_val, y_pred.round(), classes = target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. So?\n",
    "\n",
    "Compare the performance scores and confusion matrices of both models, and write down some of your observations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "source": [
    "# 22. Leave some comments about how well both Classification Systems performed and which one you would prefer to use for a task like this.\n",
    "---\n",
    "## ANSWER\n",
    "Judging only by accuracy, neural networks performed better: 0,76 vs 0,71 (for SVM), also the F1 score is higher on neural networks side: 0,84 vs 0,76 (for SVM)\n",
    "\n",
    "But, since our main task is to detect ill people with diabetes, I would prefer <b>SVM model</b>, because its Recall is higher than the one from neural nets: 0,73 (SVM) vs 0,60 (NN). Recall is important for us because it is the fraction of the total amount of relevant instances that were actually retrieved. This means, that using SVM, we will more likely find ill people with Diabetes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
